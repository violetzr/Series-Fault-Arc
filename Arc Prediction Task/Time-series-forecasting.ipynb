{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd63da",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:34.721313Z",
     "iopub.status.busy": "2025-03-04T04:04:34.721103Z",
     "iopub.status.idle": "2025-03-04T04:04:41.318375Z",
     "shell.execute_reply": "2025-03-04T04:04:41.317675Z"
    },
    "papermill": {
     "duration": 6.601829,
     "end_time": "2025-03-04T04:04:41.319895",
     "exception": false,
     "start_time": "2025-03-04T04:04:34.718066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from predictdata.utils.tools import dotdict\n",
    "# from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import torchmetrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0572a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:41.326286Z",
     "iopub.status.busy": "2025-03-04T04:04:41.325933Z",
     "iopub.status.idle": "2025-03-04T04:04:41.382109Z",
     "shell.execute_reply": "2025-03-04T04:04:41.381434Z"
    },
    "papermill": {
     "duration": 0.060509,
     "end_time": "2025-03-04T04:04:41.383266",
     "exception": false,
     "start_time": "2025-03-04T04:04:41.322757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' \n",
    "args.data = 'custom' # data\n",
    "args.root_path = '/kaggle/input/predictdata' # root path of data file\n",
    "args.data_path = 'R_predict.csv' # data file\n",
    "args.features = 'S' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'value' # target feature in S or MS task\n",
    "args.freq = 's' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 300 # input sequence length of Informer encoder\n",
    "args.label_len = 50 # start token length of Informer decoder\n",
    "args.pred_len = 100 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 1 # encoder input size\n",
    "args.dec_in = 1 # decoder input size\n",
    "args.c_out = 1 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 2 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "\n",
    "args.batch_size = 128\n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 100\n",
    "args.patience = 10\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a736a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:41.389369Z",
     "iopub.status.busy": "2025-03-04T04:04:41.389122Z",
     "iopub.status.idle": "2025-03-04T04:04:41.393733Z",
     "shell.execute_reply": "2025-03-04T04:04:41.392995Z"
    },
    "papermill": {
     "duration": 0.008799,
     "end_time": "2025-03-04T04:04:41.394850",
     "exception": false,
     "start_time": "2025-03-04T04:04:41.386051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "# args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ','').split(',')]#stack informer用\n",
    "args.detail_freq = args.freq#做预测的时候用，为啥要这样操作\n",
    "args.freq = args.freq[-1:]#切片，只选最后一个元素，导致时间间隔写30m，切成了m按月来计算\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e8eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:41.400582Z",
     "iopub.status.busy": "2025-03-04T04:04:41.400369Z",
     "iopub.status.idle": "2025-03-04T04:04:44.937515Z",
     "shell.execute_reply": "2025-03-04T04:04:44.936613Z"
    },
    "papermill": {
     "duration": 3.541453,
     "end_time": "2025-03-04T04:04:44.938878",
     "exception": false,
     "start_time": "2025-03-04T04:04:41.397425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb \n",
    "wandb.login(key=\"\") \n",
    "wandb.init(project=\"predict-project\",config=args,name='R_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52f6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:44.946717Z",
     "iopub.status.busy": "2025-03-04T04:04:44.946487Z",
     "iopub.status.idle": "2025-03-04T04:04:45.046880Z",
     "shell.execute_reply": "2025-03-04T04:04:45.045983Z"
    },
    "papermill": {
     "duration": 0.10604,
     "end_time": "2025-03-04T04:04:45.048416",
     "exception": false,
     "start_time": "2025-03-04T04:04:44.942376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from predictdata.data.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
    "from predictdata.exp.exp_basic import Exp_Basic\n",
    "from predictdata.models.model import Informer, InformerStack\n",
    "\n",
    "from predictdata.utils.tools import EarlyStopping, adjust_learning_rate\n",
    "from predictdata.utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class Exp_Informer(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Informer, self).__init__(args)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'informer':Informer,\n",
    "            'informerstack':InformerStack,#想加模型从这里加个字典\n",
    "        }\n",
    "        if self.args.model=='informer' or self.args.model=='informerstack':\n",
    "            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n",
    "            model = model_dict[self.args.model](\n",
    "                self.args.enc_in,\n",
    "                self.args.dec_in, \n",
    "                self.args.c_out, \n",
    "                self.args.seq_len, \n",
    "                self.args.label_len,\n",
    "                self.args.pred_len, \n",
    "                self.args.factor,\n",
    "                self.args.d_model, \n",
    "                self.args.n_heads, \n",
    "                e_layers, # self.args.e_layers,\n",
    "                self.args.d_layers, \n",
    "                self.args.d_ff,\n",
    "                self.args.dropout, \n",
    "                self.args.attn,\n",
    "                self.args.embed,\n",
    "                self.args.freq,\n",
    "                self.args.activation,\n",
    "                self.args.output_attention,\n",
    "                self.args.distil,\n",
    "                self.args.mix,\n",
    "                self.device\n",
    "            ).float()\n",
    "        \n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        args = self.args\n",
    "\n",
    "        data_dict = {\n",
    "            'Solar':Dataset_Custom,\n",
    "            'custom':Dataset_Custom,\n",
    "        }\n",
    "        Data = data_dict[self.args.data]\n",
    "        timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        elif flag=='pred':\n",
    "            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "            Data = Dataset_Pred\n",
    "        else:\n",
    "            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],#在这存的SIZE\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "             # 不做标准化\n",
    "            scale=False,\n",
    "            freq=freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "    \n",
    "    def _select_criterion(self):\n",
    "        criterion =  nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    def vali(self, vali_data, vali_loader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = []\n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n",
    "            pred, true = self._process_one_batch(\n",
    "                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "            loss = criterion(pred.detach().cpu(), true.detach().cpu())\n",
    "            total_loss.append(loss)\n",
    "        total_loss = np.average(total_loss)\n",
    "        self.model.train()\n",
    "        return total_loss\n",
    "\n",
    "    def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag = 'train')\n",
    "        vali_data, vali_loader = self._get_data(flag = 'val')\n",
    "        test_data, test_loader = self._get_data(flag = 'test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        #这里定义pth文件的位置\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "        \n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "        \n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion =  self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            \n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                \n",
    "                model_optim.zero_grad()\n",
    "                pred, true = self._process_one_batch(\n",
    "                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                loss = criterion(pred, true)\n",
    "                train_loss.append(loss.item())\n",
    "                # 、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、\n",
    "                if (i+1) % 100==0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time()-time_now)/iter_count\n",
    "                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "                \n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))        \n",
    "            wandb.log({\"train_loss\": train_loss, \"vali_loss\":vali_loss, \" test_loss\": test_loss})\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch+1, self.args)\n",
    "            \n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "    def test(self, setting):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        preds = []\n",
    "        trues = []\n",
    "        \n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n",
    "            pred, true = self._process_one_batch(\n",
    "                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            trues.append(true.detach().cpu().numpy())\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        print('test shape:', preds.shape, trues.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting +'/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        p=300\n",
    "        mae, mse, rmse, mape, mspe,r2,adjr2 = metric(preds, trues,p)\n",
    "#         /////////////////////////////////////////////////\n",
    "#         preds2 = torch.from_numpy(preds.squeeze(-1))  # 去掉最后一个维度，形状变为 (12160, 100)\n",
    "#         trues2= torch.from_numpy(trues.squeeze(-1))          # 去掉最后一个维度，形状变为 (12160, 100)\n",
    "#         r2=torchmetrics.functional.r2_score(preds2, trues2)\n",
    "#         adjr=rrscore(preds2, trues,300)\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "        print('mse:{}, mae:{},r2:{}, adjr:{}'.format(mse, mae,r2,adjr2))\n",
    "    \n",
    "        np.save(folder_path+'metrics.npy', np.array([mae, mse, rmse, mape, mspe,r2,adjr2]))\n",
    "        np.save(folder_path+'pred.npy', preds)\n",
    "        np.save(folder_path+'true.npy', trues)\n",
    "        metricss = [mae, mse, rmse, mape, mspe, r2, adjr2]\n",
    "        df = pd.DataFrame(metricss, index=[\"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"MSPE\", \"R2\", \"Adjusted R2\"], \n",
    "                          columns=[\"Value\"])\n",
    "        df.to_csv('评估指标.csv', header=True, index_label=\"Metricss\")\n",
    "        return\n",
    "    def rrscore(a,b,dimension):\t\t\n",
    "# a is predict, b is actual. dimension is len(train[0]).\n",
    "        aa=a.copy(); bb=b.copy()\n",
    "        if len(aa)!=len(bb):\n",
    "            print('not same length')\n",
    "            return np.nan\n",
    "\n",
    "        cc=aa-bb\n",
    "        wcpfh=sum(cc**2)\n",
    "\t\n",
    "\t# RR means R_Square\n",
    "        RR=1-sum((bb-aa)**2)/sum((bb-np.mean(bb))**2)\n",
    "\n",
    "        n=len(aa); p=dimension\n",
    "        Adjust_RR=1-(1-RR)*(n-1)/(n-p-1)\n",
    "\t# Adjust_RR means Adjust_R_Square\n",
    "\t\n",
    "        return Adjust_RR\n",
    "\n",
    "    def predict(self, setting, load=False):\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "        \n",
    "        if load:\n",
    "            path = os.path.join(self.args.checkpoints, setting)\n",
    "            best_model_path = path+'/'+'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "            aa = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "            print(aa)\n",
    "\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "                pred, true = self._process_one_batch(\n",
    "                    pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "            preds = np.array(preds)\n",
    "            preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        \n",
    "        # result save\n",
    "        folder_path = './results/' + setting +'/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        \n",
    "        np.save(folder_path+'real_prediction.npy', preds)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.float()\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "        # decoder input\n",
    "        if self.args.padding==0:\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif self.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n",
    "        # encoder - decoder\n",
    "        if self.args.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        else:\n",
    "            if self.args.output_attention:\n",
    "                outputs,attn= self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            else:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        if self.args.inverse:\n",
    "            outputs = dataset_object.inverse_transform(outputs)\n",
    "        f_dim = -1 if self.args.features=='MS' else 0\n",
    "        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n",
    "\n",
    "        return outputs, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1ad90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T04:04:45.055852Z",
     "iopub.status.busy": "2025-03-04T04:04:45.055613Z",
     "iopub.status.idle": "2025-03-04T05:32:12.915597Z",
     "shell.execute_reply": "2025-03-04T05:32:12.914754Z"
    },
    "papermill": {
     "duration": 5247.865063,
     "end_time": "2025-03-04T05:32:12.916938",
     "exception": false,
     "start_time": "2025-03-04T04:04:45.051875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp_Informer(args)\n",
    "    \n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "    \n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647d236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T05:32:12.932996Z",
     "iopub.status.busy": "2025-03-04T05:32:12.932762Z",
     "iopub.status.idle": "2025-03-04T05:32:13.483843Z",
     "shell.execute_reply": "2025-03-04T05:32:13.482987Z"
    },
    "papermill": {
     "duration": 0.563307,
     "end_time": "2025-03-04T05:32:13.488070",
     "exception": false,
     "start_time": "2025-03-04T05:32:12.924763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds=np.load('/kaggle/working/results/'+setting+'/pred.npy')\n",
    "trues=np.load('/kaggle/working/results/'+setting+'/true.npy')\n",
    "pprint(preds.shape)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(trues[:,0,-1].reshape(-1),label='true')\n",
    "plt.plot(preds[:,0,-1].reshape(-1),label='pred')\n",
    "plt.legend()\n",
    "plt.savefig('/kaggle/working/jpg'+setting+'.jpg')\n",
    "# plt.savefig('./picture/eps'+setting+'.eps')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9355c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T05:32:13.515666Z",
     "iopub.status.busy": "2025-03-04T05:32:13.515407Z",
     "iopub.status.idle": "2025-03-04T05:32:13.925318Z",
     "shell.execute_reply": "2025-03-04T05:32:13.924543Z"
    },
    "papermill": {
     "duration": 0.427384,
     "end_time": "2025-03-04T05:32:13.929227",
     "exception": false,
     "start_time": "2025-03-04T05:32:13.501843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(trues[:,0,-1].reshape(-1),label='true')\n",
    "plt.legend()\n",
    "plt.savefig('/kaggle/working/TRUEjpg'+setting+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe002d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T05:32:13.968148Z",
     "iopub.status.busy": "2025-03-04T05:32:13.967908Z",
     "iopub.status.idle": "2025-03-04T05:32:14.355435Z",
     "shell.execute_reply": "2025-03-04T05:32:14.354581Z"
    },
    "papermill": {
     "duration": 0.411146,
     "end_time": "2025-03-04T05:32:14.359381",
     "exception": false,
     "start_time": "2025-03-04T05:32:13.948235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(preds[:,0,-1].reshape(-1),label='pred')\n",
    "plt.legend()\n",
    "plt.savefig('/kaggle/working/PREDICTjpg'+setting+'.jpg')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6445291,
     "isSourceIdPinned": false,
     "sourceId": 10908245,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5263.800985,
   "end_time": "2025-03-04T05:32:16.111466",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-04T04:04:32.310481",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

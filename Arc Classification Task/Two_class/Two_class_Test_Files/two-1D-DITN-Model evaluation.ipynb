{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad4bc19",
   "metadata": {},
   "source": [
    "# 1准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02563f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "config = Namespace(\n",
    "    batch_size =64,\n",
    "    num_workers=0,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d84fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-2]])##二分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#层归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "# 、、、、、、、、、、、、、、、、、、、、\n",
    "file_path = \"../alldata.csv\"\n",
    "dfdata = MyDataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dfdata.ydata=dfdata.ydata.to(dtype=torch.int64) #使用交叉熵做损失函数时\n",
    "temp_b= torch.mean(dfdata.xdata, dim=0)\n",
    "temp_c=torch.std(dfdata.xdata, dim=0)\n",
    "dfdata.xdata= (dfdata.xdata- temp_b) / temp_c\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_val:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows操作系统\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签 \n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7963f8",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, module='torch.nn')\n",
    "\n",
    "class Inception(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters):\n",
    "        super(Inception, self).__init__()\n",
    "#         瓶颈层用于减少维度或保持维度不变以便进行后续操作\n",
    "# 当stride=1时，padding='SAME'意味着卷积后的输出与输入size保持一致\n",
    "        self.bottleneck1 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "# 不同的卷积运算与池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果将获得更好的图像表征。        \n",
    "        self.conv20 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=20,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=4,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv40 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=40,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=4,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv60 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=60,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=4,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.max_pool = torch.nn.MaxPool1d(\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        \n",
    "        self.bottleneck2 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "#         当input的维度为（N, C）时，BN将对C维归一化；当input的维度为(N, C, L) 时，归一化的维度同样为C维。\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.bottleneck1(x)\n",
    "        x1 = self.conv20(x0)\n",
    "        x2 = self.conv40(x0)\n",
    "        x3 = self.conv60(x0)\n",
    "        x4 = self.bottleneck2(self.max_pool(x))\n",
    "        y = torch.concat([x1, x2, x3, x4], dim=1)\n",
    "        y = torch.nn.functional.relu(self.batch_norm(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters):\n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        self.bottleneck = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=4 * filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        y = y + self.batch_norm(self.bottleneck(x))\n",
    "        y = torch.nn.functional.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Lambda(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.f = f\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class InceptionModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes, filters, depth):\n",
    "        super(InceptionModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.filters = filters\n",
    "        self.depth = depth\n",
    "#         self.drop=nn.Dropout(p=0.2)\n",
    "        modules = OrderedDict()\n",
    "        \n",
    "        for d in range(depth):\n",
    "            modules[f'inception_{d}'] = Inception(\n",
    "                input_size=input_size if d == 0 else 4 * filters,\n",
    "                filters=filters,\n",
    "            )\n",
    "            if d % 3 == 2:\n",
    "                modules[f'residual_{d}'] = Residual(\n",
    "                    input_size=input_size if d == 2 else 4 * filters,\n",
    "                    filters=filters,\n",
    "                )\n",
    "        \n",
    "        modules['avg_pool'] = Lambda(f=lambda x: torch.mean(x, dim=-1))\n",
    "        # modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=num_classes)\n",
    "        modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=filters)\n",
    "        modules['linear2'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "#         modules['linear3'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "        self.model = torch.nn.Sequential(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for d in range(self.depth):\n",
    "            y = self.model.get_submodule(f'inception_{d}')(x if d == 0 else y)\n",
    "            if d % 3 == 2:\n",
    "                y = self.model.get_submodule(f'residual_{d}')(x, y)\n",
    "                x = y\n",
    "        y = self.model.get_submodule('avg_pool')(y)\n",
    "        y = self.model.get_submodule('linear1')(y)\n",
    "        y = self.model.get_submodule('linear2')(y)\n",
    "#         y = F.relu(self.drop(self.model.get_submodule('linear1')(y)))\n",
    "        # y = F.relu(self.drop(self.model.get_submodule('linear2')(y)))\n",
    "#         y = self.model.get_submodule('linear3')(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUC(nn.Module):\n",
    "    'approximate AUC calculation for binary-classification task'\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        self.fp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        \n",
    "    def eval_auc(self,tp,fp):\n",
    "        tp_total = torch.sum(tp)\n",
    "        fp_total = torch.sum(fp)\n",
    "        length = len(tp)\n",
    "        tp_reverse = tp[range(length-1,-1,-1)]\n",
    "        tp_reverse_cum = torch.cumsum(tp_reverse,dim=0)-tp_reverse/2.0\n",
    "        fp_reverse = fp[range(length-1,-1,-1)]\n",
    "        \n",
    "        auc = torch.sum(torch.true_divide(tp_reverse_cum,tp_total)\n",
    "                        *torch.true_divide(fp_reverse,fp_total))\n",
    "        return auc\n",
    "        \n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        y_pred = (10000*torch.sigmoid(preds)).reshape(-1).type(torch.int)\n",
    "        y_true = targets.reshape(-1)\n",
    "        \n",
    "        tpi = self.tp-self.tp\n",
    "        fpi = self.fp-self.fp\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        for i,label in enumerate(y_true):\n",
    "            if label>=0.5:\n",
    "                tpi[y_pred[i]]+=1.0\n",
    "            else:\n",
    "                fpi[y_pred[i]]+=1.0\n",
    "        self.tp+=tpi\n",
    "        self.fp+=fpi\n",
    "        return self.eval_auc(tpi,fpi)\n",
    "          \n",
    "    def compute(self):\n",
    "        return self.eval_auc(self.tp,self.fp)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tp-=self.tp\n",
    "        self.fp-=self.fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "\n",
    "summary(net,input_data=features);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee8423",
   "metadata": {},
   "source": [
    "# 训练集、测试集评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26827df",
   "metadata": {},
   "source": [
    "# 验证集参数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c0a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    "net2 = InceptionModel(\n",
    "                input_size=1,\n",
    "                num_classes=1,\n",
    "                filters=32,\n",
    "                depth=6,\n",
    "            )\n",
    "net2.load_state_dict(torch.load('checkpoint_two_inception'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bde50b",
   "metadata": {},
   "source": [
    "support：当前行的类别在测试数据中的样本总量，如上表就是，在class 0 类别在测试集中总数量为1；<br>\n",
    "precision：精度=正确预测的个数(TP)/被预测正确的个数(TP+FP)；人话也就是模型预测的结果中有多少是预测正确的<br>\n",
    "ecall:召回率=正确预测的个数(TP)/预测个数(TP+FN)；人话也就是某个类别测试集中的总量，有多少样本预测正确了；<br>\n",
    "f1-score:F1 = 2*精度*召回率/(精度+召回率)<br>\n",
    "micro avg：计算所有数据下的指标值，假设全部数据 5 个样本中有 3 个预测正确，所以 micro avg 为 3/5=0.6<br>\n",
    "macro avg：每个类别评估指标未加权的平均值，比如准确率的 macro avg，(0.50+0.00+1.00)/3=0.5<br>\n",
    "weighted avg：加权平均，就是测试集中样本量大的，给他设置的权重大点；比如第一个值的计算方法，(0.50*1 + 0.0*1 + 1.0*3)/5 = 0.70。更好点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfe55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from torchkeras.metrics import Accuracy\n",
    "from torchkeras.metrics import Precision\n",
    "from torchkeras.metrics import Recall\n",
    "\n",
    "# from torchkeras.kerascallbacks import WandbCallback\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer= torch.optim.Adam(net2.parameters(),lr=config.lr)\n",
    "metric_dict = {\"acc\":Accuracy(),\"pre\":Precision(),\"recall\":Recall(),\"auc\":AUC()}\n",
    "model = KerasModel(net2,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metric_dict,\n",
    "                   optimizer = optimizer\n",
    "                  )   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f40fda",
   "metadata": {},
   "source": [
    "# 评估矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce4944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn.metrics import classification_report\n",
    "net2 = net2.cpu()\n",
    "net2.eval()\n",
    "preds = []\n",
    "believer=[]\n",
    "believer2=[]\n",
    "ytrue=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dl_test):\n",
    "#         preds.append(net(batch))\n",
    "        inputs,labels=batch\n",
    "        x=F.sigmoid(net2(inputs))\n",
    "#         print(x)\n",
    "        believer2.extend(x.tolist())\n",
    "        x=torch.where(x > 0.5, torch.ones_like(x),torch.zeros_like(x))\n",
    "        believer.extend(x.squeeze(1).tolist())\n",
    "        preds.extend(x.squeeze(1).tolist())\n",
    "        ytrue.extend(labels.squeeze(1).tolist())\n",
    "    pprint(len(preds)) \n",
    "    pprint(len(ytrue))\n",
    "#     pprint(preds) \n",
    "#     pprint(yhat)\n",
    "print(classification_report(ytrue,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce993c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(ytrue,preds)\n",
    "# 将混淆矩阵转换为DataFrame\n",
    "df_cm = pd.DataFrame(cm, index=['True {}'.format(i) for i in range(cm.shape[0])],columns=['Predicted {}'.format(i) for i in range(cm.shape[1])])\n",
    "pprint(df_cm)\n",
    "pprint(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2# 使用matplotlib\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax=plt.matshow(cm , cmap=plt.cm.Blues,fignum=1, aspect='auto') \n",
    "cbar=plt.colorbar(ax, fraction=0.05, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=13)\n",
    "for i in range(len(cm )): \n",
    "    for j in range(len(cm )):\n",
    "        plt.annotate(cm [i,j], xy=(i, j), horizontalalignment='center', verticalalignment='center',fontsize=20)\n",
    "plt.ylabel('真实值标签',fontsize=15)\n",
    "plt.xlabel('预测值标签',fontsize=15) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eab2a6",
   "metadata": {},
   "source": [
    "pr曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd08077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(ytrue, b3)\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.plot(precision, recall, label='label:1')\n",
    "\n",
    "plt.xlabel('召回率', fontsize=17)\n",
    "plt.ylabel('精确率', fontsize=17)\n",
    "plt.tick_params(axis='both', labelsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3be62a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AP = average_precision_score(ytrue, believer2, average='weighted')\n",
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97201e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PR\n",
    "import math\n",
    "result_matrix = [[math.exp(element) for element in row] for row in believer2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8477bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1二分类标注\n",
    "# # df = pd.DataFrame()\n",
    "tempp=np.array(ytrue)\n",
    "y_test =(tempp==0)\n",
    "# #2二分类预测置信度\n",
    "tempr=np.array(believer2)\n",
    "y_score = tempr[:,0]\n",
    "print(y_score)\n",
    "# #3计算ap\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# from sklearn.metrics import average_precision_score\n",
    "precision, recall, thresholds = precision_recall_curve(ytrue, y_score)\n",
    "AP = average_precision_score(y_test, y_score, average='weighted')\n",
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c18a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "import random\n",
    "random.seed(124)\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan', 'black', 'indianred', 'brown', 'firebrick', 'maroon', 'darkred', 'red', 'sienna', 'chocolate', 'yellow', 'olivedrab', 'yellowgreen', 'darkolivegreen', 'forestgreen', 'limegreen', 'darkgreen', 'green', 'lime', 'seagreen', 'mediumseagreen', 'darkslategray', 'darkslategrey', 'teal', 'darkcyan', 'dodgerblue', 'navy', 'darkblue', 'mediumblue', 'blue', 'slateblue', 'darkslateblue', 'mediumslateblue', 'mediumpurple', 'rebeccapurple', 'blueviolet', 'indigo', 'darkorchid', 'darkviolet', 'mediumorchid', 'purple', 'darkmagenta', 'fuchsia', 'magenta', 'orchid', 'mediumvioletred', 'deeppink', 'hotpink']\n",
    "markers = [\".\",\",\",\"o\",\"v\",\"^\",\"<\",\">\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "linestyle = ['--', '-.', '-']\n",
    "def get_line_arg():\n",
    "    '''\n",
    "    随机产生一种绘图线型\n",
    "    '''\n",
    "    line_arg = {}\n",
    "    line_arg['color'] = random.choice(colors)\n",
    "    # line_arg['marker'] = random.choice(markers)\n",
    "    line_arg['linestyle'] = random.choice(linestyle)\n",
    "    line_arg['linewidth'] = random.randint(1, 4)\n",
    "    # line_arg['markersize'] = random.randint(3, 5)\n",
    "    return line_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_line_arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "# plt.plot([0, 1], [0, 1],ls=\"--\", c='.3', linewidth=3, label='随机模型')\n",
    "# plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "# plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.xlabel('假正率',fontsize=17)\n",
    "plt.ylabel('真正率',fontsize=17)\n",
    "plt.tick_params(axis='both', labelsize=15)\n",
    "plt.rcParams['font.size'] = 22\n",
    "# plt.grid(True)\n",
    "\n",
    "auc_list = []\n",
    "# for each_class in classes:\n",
    "#     y_test = list((tempp == each_class))\n",
    "#     y_score = list(tempr[:,each_class])\n",
    "#     fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "#     plt.plot(fpr, tpr, **get_line_arg(), label='class'+str(each_class))\n",
    "#     plt.legend()\n",
    "#     auc_list.append(auc(fpr, tpr))\n",
    "fpr, tpr, threshold = roc_curve(ytrue,believer2)\n",
    "plt.plot(fpr, tpr, label='label:1')\n",
    "plt.legend()\n",
    "auc_list.append(auc(fpr, tpr))\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "# plt.savefig('各类别ROC曲线.pdf'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a43d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10757e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存1\n",
    "report=classification_report(ytrue,preds,target_names=classes, output_dict=True)\n",
    "del report['accuracy']\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fa0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbba43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 计算 AUC值 的 宏平均 和 加权平均\n",
    "macro_avg_auc = np.mean(auc_list)\n",
    "weighted_avg_auc = sum(auc_list * df_report.iloc[:-2]['support'] / len(ytrue))\n",
    "auc_list.append(macro_avg_auc)\n",
    "auc_list.append(weighted_avg_auc)\n",
    "df_report['AUC'] = auc_list\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_csv('各类别准确率评估指标.csv', index_label='类别')\n",
    "# df_report.to_csv('各类别准确率评估指标.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e35b8",
   "metadata": {},
   "source": [
    "# t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8592067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "for batch in tqdm(dl_test):\n",
    "    inputs,labels=batch\n",
    "    print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    "\n",
    "for name, module in net2.named_modules():\n",
    "    print('modules:', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#抽取中间层\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "model_trunc = create_feature_extractor(net2, return_nodes={'model.linear1': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn([1,1,5000])\n",
    "pred_logits = model_trunc(a) \n",
    "pred_logits['semantic_feature'].squeeze().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# preds = []\n",
    "# 抽取层的输出维度\n",
    "preds =torch.empty((0, 32))\n",
    "ll=torch.empty(0)\n",
    "# print(preds.shape)\n",
    "for batch in tqdm(dl_test):\n",
    "    inputs,labels=batch\n",
    "#     print(inputs.shape)\n",
    "    for a in inputs:\n",
    "#         print(a.shape)\n",
    "        a=a.unsqueeze(1)\n",
    "#         print(a.shape)\n",
    "        pred_logits=model_trunc(a)\n",
    "        tmp=pred_logits['semantic_feature'].detach()\n",
    "        preds=torch.cat((preds, tmp), dim=0)\n",
    "    ll=torch.cat((ll,labels), dim=0)\n",
    "# preds=torch.tensor(preds)\n",
    "print(preds.shape)\n",
    "print(ll.shape)\n",
    "tsne_in=np.array(preds)\n",
    "ll_in=np.array(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降维到二维和三维\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, init='pca', random_state=1)\n",
    "X_tsne_2d = tsne.fit_transform(tsne_in)\n",
    "print(X_tsne_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#二维平面可视化\n",
    "import seaborn as sns\n",
    "marker_list = ['.', ',', 'o', 'v', '^', '<', '>', '1', '2', '3', '4', '8', 's', 'p', 'P', '*', 'h', 'H', '+', 'x', 'X', 'D', 'd', '|', '_', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "class_list = np.array([0,1] ,dtype='float32')\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(class_list) # 测试集标签类别数\n",
    "palette = sns.hls_palette(n_class) # 配色方案\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for idx, typee in enumerate(class_list): # 遍历每个类别\n",
    "    # 获取颜色和点型\n",
    "    color = palette[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "\n",
    "    # 找到所有标注类别为当前类别的图像索引号\n",
    "    indices = np.where(ll_in==typee)\n",
    "    plt.scatter(X_tsne_2d[indices, 0], X_tsne_2d[indices, 1], color=color, marker=marker, label='label:'+str(typee), s=10)\n",
    "\n",
    "plt.legend(fontsize=13, markerscale=2, bbox_to_anchor=(1, 1))#2倍原图例大小，右上角\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('多维语义特征t-SNE二维降维可视化.pdf', dpi=300) # 保存图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#二维交互可视化\n",
    "import plotly.express as px\n",
    "df_2d = pd.DataFrame()\n",
    "df_2d['X'] = list(X_tsne_2d[:, 0].squeeze())\n",
    "df_2d['Y'] = list(X_tsne_2d[:, 1].squeeze())\n",
    "df_2d['标注类别名称'] = ll_in\n",
    "df_2d.to_csv('t-SNE-2D.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_2d, \n",
    "                 x='X', \n",
    "                 y='Y',\n",
    "                 color='标注类别名称', \n",
    "                 labels='标注类别名称',\n",
    "                 symbol='标注类别名称', \n",
    "                 opacity=0.8,\n",
    "                 width=1000, \n",
    "                 height=600\n",
    "                )\n",
    "# 设置排版\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "fig.write_html('语义特征t-SNE二维降维plotly可视化.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature = '标注类别名称'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "fig = px.scatter_3d(df_3d, \n",
    "                    x='X', \n",
    "                    y='Y', \n",
    "                    z='Z',\n",
    "                    color='X', \n",
    "#                     labels=show_feature,\n",
    "#                     symbol=show_feature, \n",
    "                    opacity=0.6,\n",
    "                    width=800, \n",
    "                    height=580)\n",
    "\n",
    "# 设置排版\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "fig.write_html('语义特征t-SNE三维降维plotly可视化.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

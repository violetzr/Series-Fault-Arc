{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e02a42",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-26T08:32:52.480739Z",
     "iopub.status.busy": "2025-02-26T08:32:52.480373Z",
     "iopub.status.idle": "2025-02-26T08:33:02.836054Z",
     "shell.execute_reply": "2025-02-26T08:33:02.835172Z"
    },
    "papermill": {
     "duration": 10.364406,
     "end_time": "2025-02-26T08:33:02.838263",
     "exception": false,
     "start_time": "2025-02-26T08:32:52.473857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae713373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:02.850322Z",
     "iopub.status.busy": "2025-02-26T08:33:02.850036Z",
     "iopub.status.idle": "2025-02-26T08:33:25.655876Z",
     "shell.execute_reply": "2025-02-26T08:33:25.654865Z"
    },
    "papermill": {
     "duration": 22.814467,
     "end_time": "2025-02-26T08:33:25.658167",
     "exception": false,
     "start_time": "2025-02-26T08:33:02.843700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lyhue1991/torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bbf33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:25.673241Z",
     "iopub.status.busy": "2025-02-26T08:33:25.672930Z",
     "iopub.status.idle": "2025-02-26T08:33:45.991059Z",
     "shell.execute_reply": "2025-02-26T08:33:45.989987Z"
    },
    "papermill": {
     "duration": 20.329754,
     "end_time": "2025-02-26T08:33:45.994085",
     "exception": false,
     "start_time": "2025-02-26T08:33:25.664331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09f0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:46.014700Z",
     "iopub.status.busy": "2025-02-26T08:33:46.013851Z",
     "iopub.status.idle": "2025-02-26T08:33:46.037031Z",
     "shell.execute_reply": "2025-02-26T08:33:46.036060Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.034997,
     "end_time": "2025-02-26T08:33:46.039665",
     "exception": false,
     "start_time": "2025-02-26T08:33:46.004668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainmodel VisMetri\n",
    "from torchkeras.utils import is_jupyter\n",
    "class VisMetric:\n",
    "    def __init__(self, figsize=(6, 4), save_path='history.png'):\n",
    "        \"\"\"Visualization callback for monitoring metrics\n",
    "\n",
    "        Args:\n",
    "            figsize (tuple, optional): Figure size. Defaults to (6, 4)\n",
    "            save_path (str, optional): Path to save the history plot. Defaults to 'history.png'\n",
    "        \"\"\"\n",
    "        self.figsize = (6, 4)\n",
    "        self.save_path = save_path\n",
    "        self.in_jupyter = is_jupyter()\n",
    "\n",
    "    def on_fit_start(self, model: 'KerasModel'):\n",
    "        \"\"\"Callback at the beginning of the training\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance.\n",
    "        \"\"\"\n",
    "        if not self.in_jupyter:\n",
    "            print('\\nView dynamic loss/metric plot: \\n' + os.path.abspath(self.save_path))\n",
    "        # //////////////////////////////////////\n",
    "        self.metric = model.monitor.replace('val_', '')\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        x_bounds = [0, min(10, model.epochs)]\n",
    "        title = f'best {model.monitor} = ?'\n",
    "        self.update_graph(model, title=title, x_bounds=x_bounds)\n",
    "\n",
    "    def on_train_epoch_end(self, model: 'KerasModel'):\n",
    "        \"\"\"Callback at the end of each training epoch\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def on_validation_epoch_end(self, model: \"KerasModel\"):\n",
    "        \"\"\"Callback at the end of each validation epoch\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        n = len(dfhistory)\n",
    "        x_bounds = [dfhistory['epoch'].min(), min(10 + (n // 10) * 10, model.epochs)]\n",
    "        title = self.get_title(model)\n",
    "        self.update_graph(model, title=title, x_bounds=x_bounds)\n",
    "\n",
    "    def on_fit_end(self, model: \"KerasModel\"):\n",
    "        \"\"\"Callback at the end of the entire training process\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        title = self.get_title(model)\n",
    "        self.update_graph(model, title=title)\n",
    "\n",
    "    def get_best_score(self, model: 'KerasModel'):\n",
    "        \"\"\"Get the best score and epoch.\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "\n",
    "        Returns:\n",
    "            tuple: Best epoch and best score\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        arr_scores = dfhistory[model.monitor]\n",
    "        best_score = np.max(arr_scores) if model.mode == \"max\" else np.min(arr_scores)\n",
    "        best_epoch = dfhistory.loc[arr_scores == best_score, 'epoch'].tolist()[0]\n",
    "        return (best_epoch, best_score)\n",
    "\n",
    "    def get_title(self, model: 'KerasModel'):\n",
    "        \"\"\"Get the title for the plot\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "\n",
    "        Returns:\n",
    "            str: The title.\n",
    "        \"\"\"\n",
    "        best_epoch, best_score = self.get_best_score(model)\n",
    "        title = f'best {model.monitor}={best_score:.4f} (@epoch {best_epoch})'\n",
    "        return title\n",
    "\n",
    "    def update_graph(self, model: 'KerasModel', title=None, x_bounds=None, y_bounds=None):\n",
    "        \"\"\"Update the metric plot.\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "            title (str, optional): Plot title. Defaults to None\n",
    "            x_bounds (list, optional): x-axis bounds. Defaults to None\n",
    "            y_bounds (list, optional): y-axis bounds. Defaults to None\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.plt = plt\n",
    "        if not hasattr(self, 'graph_fig'):\n",
    "            self.graph_fig, self.graph_ax = plt.subplots(1, figsize=self.figsize)\n",
    "            if self.in_jupyter:\n",
    "                self.graph_out = display(self.graph_ax.figure, display_id=True)\n",
    "        self.graph_ax.clear()\n",
    "\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        epochs = dfhistory['epoch'] if 'epoch' in dfhistory.columns else []\n",
    "\n",
    "        m1 = \"train_\" + self.metric\n",
    "        if m1 in dfhistory.columns:\n",
    "            train_metrics = dfhistory[m1]\n",
    "            self.graph_ax.plot(epochs, train_metrics, 'bo--', label=m1, clip_on=False)\n",
    "\n",
    "        m2 = 'val_' + self.metric\n",
    "        if m2 in dfhistory.columns:\n",
    "            val_metrics = dfhistory[m2]\n",
    "            self.graph_ax.plot(epochs, val_metrics, 'c^-', label=m2, clip_on=False)\n",
    "\n",
    "        if self.metric in dfhistory.columns:\n",
    "            metric_values = dfhistory[self.metric]\n",
    "            self.graph_ax.plot(epochs, metric_values, 'c^-', label=self.metric, clip_on=False)\n",
    "\n",
    "        self.graph_ax.set_xlabel(\"epoch\")\n",
    "        self.graph_ax.set_ylabel(self.metric)\n",
    "        if title:\n",
    "            self.graph_ax.set_title(title)\n",
    "            if not self.in_jupyter and hasattr(model.EpochRunner, 'progress'):\n",
    "                model.EpochRunner.progress.comment_tail = title\n",
    "        if m1 in dfhistory.columns or m2 in dfhistory.columns or self.metric in dfhistory.columns:\n",
    "            self.graph_ax.legend(loc='best')\n",
    "\n",
    "        if len(epochs) > 0:\n",
    "            best_epoch, best_score = self.get_best_score(model)\n",
    "            self.graph_ax.plot(best_epoch, best_score, 'r*', markersize=15, clip_on=False)\n",
    "\n",
    "        if x_bounds is not None: self.graph_ax.set_xlim(*x_bounds)\n",
    "        if y_bounds is not None: self.graph_ax.set_ylim(*y_bounds)\n",
    "        if self.in_jupyter:\n",
    "            self.graph_out.update(self.graph_ax.figure)\n",
    "        self.graph_fig.savefig(self.save_path)\n",
    "        self.plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e89b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:46.053383Z",
     "iopub.status.busy": "2025-02-26T08:33:46.053129Z",
     "iopub.status.idle": "2025-02-26T08:33:46.091658Z",
     "shell.execute_reply": "2025-02-26T08:33:46.091011Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.04729,
     "end_time": "2025-02-26T08:33:46.093277",
     "exception": false,
     "start_time": "2025-02-26T08:33:46.045987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#kerasmodel\n",
    "import sys,datetime\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage=\"train\", metrics_dict=None,\n",
    "                 optimizer=None, lr_scheduler=None, **kwargs):\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.stage = net, loss_fn, metrics_dict, stage\n",
    "        self.optimizer, self.lr_scheduler = optimizer, lr_scheduler\n",
    "        self.kwargs = kwargs\n",
    "        self.accelerator = accelerator\n",
    "\n",
    "        # Set the network to training mode during the training stage, and evaluation mode otherwise\n",
    "        if self.stage == 'train':\n",
    "            self.net.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        features, labels = batch\n",
    "        # Compute loss\n",
    "        with self.accelerator.autocast():\n",
    "            preds = self.net(features)\n",
    "            loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        # Backward pass and optimization (only during training)\n",
    "        if self.stage == \"train\" and self.optimizer is not None:\n",
    "            self.accelerator.backward(loss)\n",
    "\n",
    "            # Clip gradients if synchronization is enabled\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Adjust learning rate if a scheduler is provided\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            # Zero gradients for the next iteration\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # Gather loss, predictions, and labels using the accelerator\n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        all_preds = self.accelerator.gather(preds)\n",
    "        all_labels = self.accelerator.gather(labels)\n",
    "\n",
    "        # Compute and gather additional metrics\n",
    "        step_losses = {self.stage + \"_loss\": all_loss.item()}\n",
    "        step_metrics = {self.stage + \"_\" + name: metric_fn(all_preds, all_labels).item()\n",
    "                        for name, metric_fn in self.metrics_dict.items()}\n",
    "\n",
    "        # Include learning rate in metrics if available\n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "                \n",
    "        return step_losses, step_metrics\n",
    "\n",
    "class EpochRunner:\n",
    "    def __init__(self, step_runner, quiet=False):\n",
    "        self.step_runner = step_runner\n",
    "        self.stage = step_runner.stage\n",
    "        self.accelerator = step_runner.accelerator\n",
    "        self.net = step_runner.net\n",
    "        self.quiet = quiet\n",
    "\n",
    "    def __call__(self, dataloader):\n",
    "        # Determine the size of the dataset\n",
    "        n = dataloader.size if hasattr(dataloader, 'size') else len(dataloader)\n",
    "\n",
    "        # Initialize tqdm progress bar\n",
    "        loop = tqdm(enumerate(dataloader, start=1),\n",
    "                    total=n,\n",
    "                    file=sys.stdout,\n",
    "                    disable=not self.accelerator.is_local_main_process or self.quiet,\n",
    "                    ncols=100\n",
    "                    )\n",
    "        epoch_losses = {}\n",
    "\n",
    "        for step, batch in loop:\n",
    "            # Perform a step with the provided StepRunner\n",
    "            with self.accelerator.accumulate(self.net):\n",
    "                step_losses, step_metrics = self.step_runner(batch)\n",
    "                step_log = dict(step_losses, **step_metrics)\n",
    "\n",
    "                # Accumulate step losses for computing epoch losses\n",
    "                for k, v in step_losses.items():\n",
    "                    epoch_losses[k] = epoch_losses.get(k, 0.0) + v\n",
    "\n",
    "                # Update progress bar during the epoch\n",
    "                if step < n:\n",
    "                    loop.set_postfix(**step_log)\n",
    "\n",
    "                    if hasattr(self, 'progress') and self.accelerator.is_local_main_process:\n",
    "                        post_log = dict(**{'i': step, 'n': n}, **step_log)\n",
    "                        self.progress.set_postfix(**post_log)\n",
    "\n",
    "                # Compute and display epoch-level metrics at the end of the epoch\n",
    "                elif step == n:\n",
    "                    epoch_metrics = step_metrics\n",
    "                    epoch_metrics.update({self.stage + \"_\" + name: metric_fn.compute().item()\n",
    "                                          for name, metric_fn in self.step_runner.metrics_dict.items()})\n",
    "                    epoch_losses = {k: v / step for k, v in epoch_losses.items()}\n",
    "                    epoch_log = dict(epoch_losses, **epoch_metrics)\n",
    "                    loop.set_postfix(**epoch_log)\n",
    "\n",
    "                    # Update progress bar if available\n",
    "                    if hasattr(self, 'progress') and self.accelerator.is_local_main_process:\n",
    "                        post_log = dict(**{'i': step, 'n': n}, **epoch_log)\n",
    "                        self.progress.set_postfix(**post_log)\n",
    "\n",
    "                    # Reset stateful metrics for the next epoch\n",
    "                    for name, metric_fn in self.step_runner.metrics_dict.items():\n",
    "                        metric_fn.reset()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        return epoch_log\n",
    "\n",
    "class KerasModel(torch.nn.Module):\n",
    "    StepRunner, EpochRunner = StepRunner, EpochRunner\n",
    "\n",
    "    def __init__(self, net, loss_fn, metrics_dict=None, optimizer=None, lr_scheduler=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.net, self.loss_fn, self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict)\n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.net.parameters(), lr=3e-4)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.kwargs = kwargs\n",
    "        self.from_scratch = True\n",
    "\n",
    "    def save_ckpt(self, ckpt_path=None, accelerator=None):\n",
    "        accelerator = accelerator if accelerator is not None else self.accelerator\n",
    "        net_dict = accelerator.get_state_dict(self.net)\n",
    "        accelerator.save(net_dict, ckpt_path if ckpt_path is not None else self.ckpt_path)\n",
    "\n",
    "    def load_ckpt(self, ckpt_path=None):\n",
    "        self.net.load_state_dict(torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n",
    "                                            map_location='cpu'))\n",
    "        self.from_scratch = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.forward(x)\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint',\n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None,\n",
    "            plot=True, wandb=False, quiet=None,\n",
    "            mixed_precision='no', cpu=False, gradient_accumulation_steps=1):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        Args:\n",
    "            train_data: Training data\n",
    "            val_data: Validation data\n",
    "            epochs: Number of training epochs\n",
    "            ckpt_path: Path to save model checkpoints\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            monitor: Metric to monitor for early stopping\n",
    "            mode: 'min' for minimizing the monitor metric, 'max' for maximizing\n",
    "            callbacks: List of callback functions\n",
    "            plot: Whether to plot training progress\n",
    "            wandb: Whether to use WandB for logging\n",
    "            quiet: Whether to suppress training progress logs\n",
    "            mixed_precision: Mixed precision training ('no', 'O1', 'O2', 'O3')\n",
    "            cpu: Use CPU for training\n",
    "            gradient_accumulation_steps: Number of steps to accumulate gradients before optimizer step\n",
    "\n",
    "        Returns:\n",
    "            DataFrame containing training history.\n",
    "        \"\"\"\n",
    "        self.__dict__.update(locals())\n",
    "        from accelerate import Accelerator\n",
    "        from torchkeras.utils import colorful, is_jupyter\n",
    "\n",
    "        self.accelerator = Accelerator(mixed_precision=mixed_precision, cpu=cpu,\n",
    "                                       gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "\n",
    "        device = str(self.accelerator.device)\n",
    "        device_type = '🐌' if 'cpu' in device else ('⚡️' if 'cuda' in device else '🚀')\n",
    "        self.accelerator.print(\n",
    "            colorful(\"<<<<<< \" + device_type + \" \" + device + \" is used >>>>>>\"))\n",
    "\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.optimizer, self.lr_scheduler = self.accelerator.prepare(\n",
    "            self.net, self.loss_fn, self.metrics_dict, self.optimizer, self.lr_scheduler)\n",
    "\n",
    "        for key in self.kwargs:\n",
    "            self.kwargs[key] = self.accelerator.prepare(self.kwargs[key])\n",
    "\n",
    "        train_dataloader, val_dataloader = self.accelerator.prepare(train_data, val_data)\n",
    "        train_dataloader.size = train_data.size if hasattr(train_data, 'size') else len(train_data)\n",
    "        train_dataloader.size = min(train_dataloader.size, len(train_dataloader))\n",
    "\n",
    "        if val_data:\n",
    "            val_dataloader.size = val_data.size if hasattr(val_data, 'size') else len(val_data)\n",
    "            val_dataloader.size = min(val_dataloader.size, len(val_dataloader))\n",
    "\n",
    "        self.history = {}\n",
    "        callbacks = callbacks if callbacks is not None else []\n",
    "\n",
    "        if bool(plot):\n",
    "            from torchkeras.kerascallbacks import VisProgress\n",
    "            callbacks = [VisMetric(), VisProgress()] + callbacks\n",
    "\n",
    "        if wandb != False:\n",
    "            from torchkeras.kerascallbacks import WandbCallback\n",
    "            project = wandb if isinstance(wandb, str) else 'torchkeras'\n",
    "            callbacks.append(WandbCallback(project=project))\n",
    "\n",
    "        self.callbacks = [self.accelerator.prepare(x) for x in callbacks]\n",
    "\n",
    "        if self.accelerator.is_local_main_process:\n",
    "            [cb.on_fit_start(model=self) for cb in self.callbacks if hasattr(cb, 'on_fit_start')]\n",
    "\n",
    "        start_epoch = 1 if self.from_scratch else 0\n",
    "\n",
    "        if bool(plot) or quiet is None:\n",
    "            quiet = True\n",
    "\n",
    "        quiet_fn = (lambda epoch: quiet) if isinstance(quiet, bool) else (\n",
    "            (lambda epoch: epoch > quiet) if isinstance(quiet, int) else quiet)\n",
    "\n",
    "        for epoch in range(start_epoch, epochs + 1):\n",
    "            should_quiet = quiet_fn(epoch)\n",
    "\n",
    "            if not should_quiet:\n",
    "                nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                self.accelerator.print(\"\\n\" + \"==========\" * 8 + \"%s\" % nowtime)\n",
    "                self.accelerator.print(\"Epoch {0} / {1}\".format(epoch, epochs) + \"\\n\")\n",
    "\n",
    "            # 1，train -------------------------------------------------\n",
    "            train_step_runner = self.StepRunner(\n",
    "                net=self.net,\n",
    "                loss_fn=self.loss_fn,\n",
    "                accelerator=self.accelerator,\n",
    "                stage=\"train\",\n",
    "                metrics_dict=deepcopy(self.metrics_dict),\n",
    "                optimizer=self.optimizer if epoch > 0 else None,\n",
    "                lr_scheduler=self.lr_scheduler if epoch > 0 else None,\n",
    "                **self.kwargs\n",
    "            )\n",
    "\n",
    "            train_epoch_runner = self.EpochRunner(train_step_runner, should_quiet)\n",
    "            train_metrics = {'epoch': epoch}\n",
    "            train_metrics.update(train_epoch_runner(train_dataloader))\n",
    "\n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            if self.accelerator.is_local_main_process:\n",
    "                [cb.on_train_epoch_end(model=self) for cb in self.callbacks\n",
    "                 if hasattr(cb, 'on_train_epoch_end')]\n",
    "            # 2，validate -------------------------------------------------\n",
    "            if val_dataloader is not None:\n",
    "                val_step_runner = self.StepRunner(\n",
    "                    net = self.net,\n",
    "                    loss_fn = self.loss_fn,\n",
    "                    accelerator = self.accelerator,\n",
    "                    stage=\"val\",\n",
    "                    metrics_dict= deepcopy(self.metrics_dict),\n",
    "                    **self.kwargs\n",
    "                )\n",
    "                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_dataloader)\n",
    "\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "                \n",
    "            if self.accelerator.is_local_main_process:\n",
    "                [cb.on_validation_epoch_end(model = self) for cb in self.callbacks \n",
    "                 if hasattr(cb,'on_validation_epoch_end')]\n",
    "\n",
    "            # 3，early-stopping -------------------------------------------------\n",
    "            self.accelerator.wait_for_everyone()\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "\n",
    "            if best_score_idx==len(arr_scores)-1 and self.accelerator.is_local_main_process:\n",
    "                self.save_ckpt(ckpt_path,accelerator = self.accelerator)\n",
    "                if not should_quiet:\n",
    "                    self.accelerator.print(colorful(\"<<<<<< reach best {0} : {1} >>>>>>\".format(\n",
    "                        monitor,arr_scores[best_score_idx])))\n",
    "\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                break\n",
    "                \n",
    "        if self.accelerator.is_local_main_process:   \n",
    "            dfhistory = pd.DataFrame(self.history)\n",
    "            [cb.on_fit_end(model = self) for cb in self.callbacks \n",
    "                 if hasattr(cb,'on_fit_end')]\n",
    "            if epoch<epochs:\n",
    "                self.accelerator.print(colorful(\n",
    "                        \"<<<<<< {} without improvement in {} epoch,\"\"early stopping >>>>>> \\n\"\n",
    "                    ).format(monitor,patience))\n",
    "            self.net = self.accelerator.unwrap_model(self.net)\n",
    "            self.net.cpu()\n",
    "            self.load_ckpt(ckpt_path)\n",
    "            return dfhistory\n",
    "        \n",
    "    def evaluate(self, val_data, quiet=False):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data\n",
    "\n",
    "        Args:\n",
    "            val_data: Validation data\n",
    "            quiet: Whether to suppress evaluation progress logs\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        # Ensure accelerator is available or create a new one\n",
    "        from accelerate import Accelerator\n",
    "        accelerator = Accelerator() if not hasattr(self, 'accelerator') else self.accelerator\n",
    "\n",
    "        # Prepare model, loss function, and metrics for evaluation\n",
    "        self.net, self.loss_fn, self.metrics_dict = accelerator.prepare(\n",
    "            self.net, self.loss_fn, self.metrics_dict)\n",
    "\n",
    "        val_data = accelerator.prepare(val_data)\n",
    "\n",
    "        # Initialize StepRunner for validation\n",
    "        val_step_runner = self.StepRunner(net=self.net, stage=\"val\",\n",
    "                                          loss_fn=self.loss_fn, metrics_dict=deepcopy(self.metrics_dict),\n",
    "                                          accelerator=accelerator)\n",
    "\n",
    "        # Initialize EpochRunner for validation\n",
    "        val_epoch_runner = self.EpochRunner(val_step_runner, quiet=quiet)\n",
    "\n",
    "        # Evaluate on validation data without gradient computation\n",
    "        with torch.no_grad():\n",
    "            val_metrics = val_epoch_runner(val_data)\n",
    "\n",
    "        return val_metrics\n",
    "    \n",
    "    def fit_ddp(self, num_processes, train_data,\n",
    "                val_data=None, epochs=10, ckpt_path='checkpoint',\n",
    "                patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None,\n",
    "                plot=True, wandb=False, quiet=None,\n",
    "                mixed_precision='no', cpu=False, gradient_accumulation_steps=1):\n",
    "        \"\"\"\n",
    "        Distributed Data Parallel (DDP) training for the model.\n",
    "\n",
    "        Args:\n",
    "            num_processes: Number of processes for DDP\n",
    "            train_data: Training data\n",
    "            val_data: Validation data\n",
    "            epochs: Number of training epochs\n",
    "            ckpt_path: Path to save model checkpoints\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            monitor: Metric to monitor for early stopping\n",
    "            mode: 'min' for minimizing the monitor metric, 'max' for maximizing\n",
    "            callbacks: List of callback functions\n",
    "            plot: Whether to plot training progress\n",
    "            wandb: Whether to use WandB for logging\n",
    "            quiet: Whether to suppress training progress logs\n",
    "            mixed_precision: Mixed precision training ('no', 'O1', 'O2', 'O3')\n",
    "            cpu: Use CPU for training\n",
    "            gradient_accumulation_steps: Number of steps to accumulate gradients before optimizer step\n",
    "        \"\"\"\n",
    "        # Import notebook_launcher from accelerate\n",
    "        from accelerate import notebook_launcher\n",
    "\n",
    "        # Create a tuple of arguments for the fit method\n",
    "        args = (train_data, val_data, epochs, ckpt_path, patience, monitor, mode,\n",
    "                callbacks, plot, wandb, quiet, mixed_precision, cpu, gradient_accumulation_steps)\n",
    "\n",
    "        # Launch the fit method using notebook_launcher\n",
    "        notebook_launcher(self.fit, args, num_processes=num_processes)\n",
    "    \n",
    "    def evaluate_ddp(self, num_processes, val_data, quiet=False):\n",
    "        \"\"\"\n",
    "        Distributed Data Parallel (DDP) evaluation for the model\n",
    "\n",
    "        Args:\n",
    "            num_processes: Number of processes for DDP\n",
    "            val_data: Validation data.\n",
    "            quiet: Whether to suppress evaluation progress logs\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        # Import notebook_launcher from accelerate\n",
    "        from accelerate import notebook_launcher\n",
    "\n",
    "        # Create a tuple of arguments for the evaluate method\n",
    "        args = (val_data, quiet)\n",
    "\n",
    "        # Launch the evaluate method using notebook_launcher\n",
    "        notebook_launcher(self.evaluate, args, num_processes=num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7fa7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:46.105939Z",
     "iopub.status.busy": "2025-02-26T08:33:46.105696Z",
     "iopub.status.idle": "2025-02-26T08:33:46.120762Z",
     "shell.execute_reply": "2025-02-26T08:33:46.119926Z"
    },
    "papermill": {
     "duration": 0.023529,
     "end_time": "2025-02-26T08:33:46.122403",
     "exception": false,
     "start_time": "2025-02-26T08:33:46.098874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, module='torch.nn')\n",
    "\n",
    "class Inception(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters,dilation):\n",
    "        super(Inception, self).__init__()\n",
    "# 瓶颈层用于减少维度或保持维度不变以便进行后续操作\n",
    "# 当stride=1时，padding='SAME'意味着卷积后的输出与输入size保持一致\n",
    "        self.bottleneck1 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "# 不同的卷积运算与池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果将获得更好的图像表征。        \n",
    "        self.conv20 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=20,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=dilation,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv40 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=40,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=dilation,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv60 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=60,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=dilation,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.max_pool = torch.nn.MaxPool1d(\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        \n",
    "        self.bottleneck2 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "#         当input的维度为（N, C）时，BN将对C维归一化；当input的维度为(N, C, L) 时，归一化的维度同样为C维。\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.bottleneck1(x)\n",
    "        x1 = self.conv20(x0)\n",
    "        x2 = self.conv40(x0)\n",
    "        x3 = self.conv60(x0)\n",
    "        x4 = self.bottleneck2(self.max_pool(x))\n",
    "        y = torch.concat([x1, x2, x3, x4], dim=1)\n",
    "        y = torch.nn.functional.relu(self.batch_norm(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters):\n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        self.bottleneck = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=4 * filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        y = y + self.batch_norm(self.bottleneck(x))\n",
    "        y = torch.nn.functional.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Lambda(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.f = f\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class InceptionModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes, filters, depth,dilation=0,dropout=0):\n",
    "        super(InceptionModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.filters = filters\n",
    "        self.depth = depth\n",
    "        self.dilation = dilation\n",
    "        # \n",
    "        self.drop=nn.Dropout(p=dropout)\n",
    "        modules = OrderedDict()\n",
    "        \n",
    "        for d in range(depth):\n",
    "            modules[f'inception_{d}'] = Inception(\n",
    "                input_size=input_size if d == 0 else 4 * filters,\n",
    "                filters=filters,\n",
    "                dilation=dilation\n",
    "            )\n",
    "            if d % 3 == 2:\n",
    "                modules[f'residual_{d}'] = Residual(\n",
    "                    input_size=input_size if d == 2 else 4 * filters,\n",
    "                    filters=filters\n",
    "                 \n",
    "                )\n",
    "        \n",
    "        modules['avg_pool'] = Lambda(f=lambda x: torch.mean(x, dim=-1))\n",
    "        # modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=num_classes)\n",
    "        modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=filters)\n",
    "        modules['linear2'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "#         modules['linear3'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "        self.model = torch.nn.Sequential(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for d in range(self.depth):\n",
    "            y = self.model.get_submodule(f'inception_{d}')(x if d == 0 else y)\n",
    "            if d % 3 == 2:\n",
    "                y = self.model.get_submodule(f'residual_{d}')(x, y)\n",
    "                x = y\n",
    "        y = self.model.get_submodule('avg_pool')(y)\n",
    "        y = self.model.get_submodule('linear1')(y)\n",
    "        y = self.drop(F.relu(y))\n",
    "        y = self.model.get_submodule('linear2')(y)\n",
    "#         y = F.relu(self.drop(self.model.get_submodule('linear1')(y)))\n",
    "        # y = F.relu(self.drop(self.model.get_submodule('linear2')(y)))\n",
    "#         y = self.model.get_submodule('linear3')(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6644f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:46.134189Z",
     "iopub.status.busy": "2025-02-26T08:33:46.133937Z",
     "iopub.status.idle": "2025-02-26T08:33:48.032078Z",
     "shell.execute_reply": "2025-02-26T08:33:48.030995Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.906376,
     "end_time": "2025-02-26T08:33:48.034021",
     "exception": false,
     "start_time": "2025-02-26T08:33:46.127645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb \n",
    "wandb.login(key=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26570b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:48.047345Z",
     "iopub.status.busy": "2025-02-26T08:33:48.047054Z",
     "iopub.status.idle": "2025-02-26T08:33:48.058804Z",
     "shell.execute_reply": "2025-02-26T08:33:48.057917Z"
    },
    "papermill": {
     "duration": 0.021043,
     "end_time": "2025-02-26T08:33:48.061118",
     "exception": false,
     "start_time": "2025-02-26T08:33:48.040075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from torch.optim import lr_scheduler\n",
    "# \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# \n",
    "config = Namespace(\n",
    "    project_name = \"two-inception\",\n",
    "    file_path = \"/alldata.csv\",\n",
    "    batch_size =128,\n",
    "    dropout_p = 0.5,\n",
    "    lr = 1e-3,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 200,\n",
    "    ckpt_path = 'checkpoint',\n",
    "    num_workers=0,\n",
    "    filters=32,\n",
    "    dilation=4,\n",
    "    depth=6,\n",
    "    name='two-1dditn'\n",
    ")\n",
    "\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733121a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:33:48.080341Z",
     "iopub.status.busy": "2025-02-26T08:33:48.079692Z",
     "iopub.status.idle": "2025-02-26T08:34:33.418186Z",
     "shell.execute_reply": "2025-02-26T08:34:33.416659Z"
    },
    "papermill": {
     "duration": 45.348995,
     "end_time": "2025-02-26T08:34:33.420617",
     "exception": false,
     "start_time": "2025-02-26T08:33:48.071622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-2]])##二分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#最大最小归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dfdata = MyDataset(config.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2e56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:34:33.435401Z",
     "iopub.status.busy": "2025-02-26T08:34:33.435077Z",
     "iopub.status.idle": "2025-02-26T08:35:15.262588Z",
     "shell.execute_reply": "2025-02-26T08:35:15.261867Z"
    },
    "papermill": {
     "duration": 41.837443,
     "end_time": "2025-02-26T08:35:15.264623",
     "exception": false,
     "start_time": "2025-02-26T08:34:33.427180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_b= torch.mean(dfdata.xdata, dim=0)\n",
    "temp_c=torch.std(dfdata.xdata, dim=0)\n",
    "dfdata.xdata= (dfdata.xdata- temp_b) /temp_c\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ffd53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:15.289426Z",
     "iopub.status.busy": "2025-02-26T08:35:15.289135Z",
     "iopub.status.idle": "2025-02-26T08:35:15.293675Z",
     "shell.execute_reply": "2025-02-26T08:35:15.292885Z"
    },
    "papermill": {
     "duration": 0.012811,
     "end_time": "2025-02-26T08:35:15.295223",
     "exception": false,
     "start_time": "2025-02-26T08:35:15.282412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963387fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:15.307768Z",
     "iopub.status.busy": "2025-02-26T08:35:15.307185Z",
     "iopub.status.idle": "2025-02-26T08:35:15.315025Z",
     "shell.execute_reply": "2025-02-26T08:35:15.314349Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015576,
     "end_time": "2025-02-26T08:35:15.316484",
     "exception": false,
     "start_time": "2025-02-26T08:35:15.300908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AUC(nn.Module):\n",
    "    'approximate AUC calculation for binary-classification task'\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        self.fp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        \n",
    "    def eval_auc(self,tp,fp):\n",
    "        tp_total = torch.sum(tp)\n",
    "        fp_total = torch.sum(fp)\n",
    "        length = len(tp)\n",
    "        tp_reverse = tp[range(length-1,-1,-1)]\n",
    "        tp_reverse_cum = torch.cumsum(tp_reverse,dim=0)-tp_reverse/2.0\n",
    "        fp_reverse = fp[range(length-1,-1,-1)]\n",
    "        \n",
    "        auc = torch.sum(torch.true_divide(tp_reverse_cum,tp_total)\n",
    "                        *torch.true_divide(fp_reverse,fp_total))\n",
    "        return auc\n",
    "        \n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        y_pred = (10000*torch.sigmoid(preds)).reshape(-1).type(torch.int)\n",
    "        y_true = targets.reshape(-1)\n",
    "        \n",
    "        tpi = self.tp-self.tp\n",
    "        fpi = self.fp-self.fp\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        for i,label in enumerate(y_true):\n",
    "            if label>=0.5:\n",
    "                tpi[y_pred[i]]+=1.0\n",
    "            else:\n",
    "                fpi[y_pred[i]]+=1.0\n",
    "        self.tp+=tpi\n",
    "        self.fp+=fpi\n",
    "        return self.eval_auc(tpi,fpi)\n",
    "          \n",
    "    def compute(self):\n",
    "        return self.eval_auc(self.tp,self.fp)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tp-=self.tp\n",
    "        self.fp-=self.fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd5793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:15.328770Z",
     "iopub.status.busy": "2025-02-26T08:35:15.328514Z",
     "iopub.status.idle": "2025-02-26T08:35:15.352125Z",
     "shell.execute_reply": "2025-02-26T08:35:15.351313Z"
    },
    "papermill": {
     "duration": 0.031481,
     "end_time": "2025-02-26T08:35:15.353583",
     "exception": false,
     "start_time": "2025-02-26T08:35:15.322102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for features,labels in dl_val:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69381c66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:15.378402Z",
     "iopub.status.busy": "2025-02-26T08:35:15.377960Z",
     "iopub.status.idle": "2025-02-26T08:35:15.467496Z",
     "shell.execute_reply": "2025-02-26T08:35:15.466582Z"
    },
    "papermill": {
     "duration": 0.097997,
     "end_time": "2025-02-26T08:35:15.469202",
     "exception": false,
     "start_time": "2025-02-26T08:35:15.371205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net=InceptionModel(\n",
    "                input_size=1,\n",
    "                num_classes=1,\n",
    "                filters=config.filters,\n",
    "                depth=config.depth,\n",
    "                dilation=config.dilation,\n",
    "                dropout=config.dropout_p\n",
    "                \n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3025a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:15.481909Z",
     "iopub.status.busy": "2025-02-26T08:35:15.481634Z",
     "iopub.status.idle": "2025-02-26T08:35:33.616914Z",
     "shell.execute_reply": "2025-02-26T08:35:33.615080Z"
    },
    "papermill": {
     "duration": 18.143892,
     "end_time": "2025-02-26T08:35:33.618962",
     "exception": false,
     "start_time": "2025-02-26T08:35:15.475070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(net,input_data=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf50da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:33.632956Z",
     "iopub.status.busy": "2025-02-26T08:35:33.632626Z",
     "iopub.status.idle": "2025-02-26T08:35:34.033248Z",
     "shell.execute_reply": "2025-02-26T08:35:34.032317Z"
    },
    "papermill": {
     "duration": 0.409772,
     "end_time": "2025-02-26T08:35:34.035259",
     "exception": false,
     "start_time": "2025-02-26T08:35:33.625487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchkeras.metrics import Accuracy\n",
    "from torchkeras.metrics import Precision\n",
    "from torchkeras.metrics import Recall\n",
    "from torchkeras.kerascallbacks import WandbCallback\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr=config.lr)\n",
    "lr_scheduler2 = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "metric_dict = {\"acc\":Accuracy(),\"pre\":Precision(),\"recall\":Recall(),\"auc\":AUC()}\n",
    "model = KerasModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metric_dict,\n",
    "                   optimizer = optimizer,\n",
    "                   lr_scheduler=lr_scheduler2\n",
    "                  )   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b13c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:34.049242Z",
     "iopub.status.busy": "2025-02-26T08:35:34.048949Z",
     "iopub.status.idle": "2025-02-26T08:35:34.053076Z",
     "shell.execute_reply": "2025-02-26T08:35:34.052296Z"
    },
    "papermill": {
     "duration": 0.012822,
     "end_time": "2025-02-26T08:35:34.054679",
     "exception": false,
     "start_time": "2025-02-26T08:35:34.041857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchkeras.kerascallbacks import WandbCallback\n",
    "wandb_cb = WandbCallback(project=config.project_name,\n",
    "                         config=config,\n",
    "                         name=None,\n",
    "                         save_code=True,\n",
    "                         save_ckpt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c63a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T08:35:34.067435Z",
     "iopub.status.busy": "2025-02-26T08:35:34.067182Z",
     "iopub.status.idle": "2025-02-26T11:55:23.918138Z",
     "shell.execute_reply": "2025-02-26T11:55:23.916860Z"
    },
    "papermill": {
     "duration": 11989.85991,
     "end_time": "2025-02-26T11:55:23.920714",
     "exception": false,
     "start_time": "2025-02-26T08:35:34.060804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfhistory = model.fit(\n",
    "      train_data=dl_train,\n",
    "      val_data=dl_val,\n",
    "      epochs=config.epochs,\n",
    "      ckpt_path='checkpoint',\n",
    "      patience=16,\n",
    "      monitor='val_acc',\n",
    "      mode='max',\n",
    "      callbacks = [wandb_cb]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5940593,
     "sourceId": 10855665,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12157.531808,
   "end_time": "2025-02-26T11:55:27.443844",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-26T08:32:49.912036",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

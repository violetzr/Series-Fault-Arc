{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903ffe77",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:00.628428Z",
     "iopub.status.busy": "2024-12-16T14:07:00.628120Z",
     "iopub.status.idle": "2024-12-16T14:07:00.632394Z",
     "shell.execute_reply": "2024-12-16T14:07:00.631609Z"
    },
    "papermill": {
     "duration": 0.012019,
     "end_time": "2024-12-16T14:07:00.633988",
     "exception": false,
     "start_time": "2024-12-16T14:07:00.621969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use n,x,5000\n",
    "#use 1dcnn\n",
    "#two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334f6d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:00.644036Z",
     "iopub.status.busy": "2024-12-16T14:07:00.643633Z",
     "iopub.status.idle": "2024-12-16T14:07:10.599763Z",
     "shell.execute_reply": "2024-12-16T14:07:10.598874Z"
    },
    "papermill": {
     "duration": 9.963024,
     "end_time": "2024-12-16T14:07:10.601684",
     "exception": false,
     "start_time": "2024-12-16T14:07:00.638660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\r\n",
      "Collecting accelerate\r\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.25.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\r\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: accelerate\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 0.34.2\r\n",
      "    Uninstalling accelerate-0.34.2:\r\n",
      "      Successfully uninstalled accelerate-0.34.2\r\n",
      "Successfully installed accelerate-1.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cced851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:10.614415Z",
     "iopub.status.busy": "2024-12-16T14:07:10.614091Z",
     "iopub.status.idle": "2024-12-16T14:07:33.071242Z",
     "shell.execute_reply": "2024-12-16T14:07:33.070418Z"
    },
    "papermill": {
     "duration": 22.466196,
     "end_time": "2024-12-16T14:07:33.073191",
     "exception": false,
     "start_time": "2024-12-16T14:07:10.606995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lyhue1991/torchkeras\r\n",
      "  Cloning https://github.com/lyhue1991/torchkeras to /tmp/pip-req-build-tgebm5r6\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lyhue1991/torchkeras /tmp/pip-req-build-tgebm5r6\r\n",
      "  Resolved https://github.com/lyhue1991/torchkeras to commit e76056051ae529662ecbf48b53da5be12094567b\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: torchkeras\r\n",
      "  Building wheel for torchkeras (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torchkeras: filename=torchkeras-4.0.3-py3-none-any.whl size=45309457 sha256=5a20a24c2972a966ccc8555bae9eca98c68564d6479d750114ea97792a5958c4\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zvjqbnz1/wheels/57/53/ef/298ba6f59ff9f8b295a17a3f226848e6062b17e19aab3dc7d2\r\n",
      "Successfully built torchkeras\r\n",
      "Installing collected packages: torchkeras\r\n",
      "Successfully installed torchkeras-4.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lyhue1991/torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42d58e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:33.086197Z",
     "iopub.status.busy": "2024-12-16T14:07:33.085885Z",
     "iopub.status.idle": "2024-12-16T14:07:52.178850Z",
     "shell.execute_reply": "2024-12-16T14:07:52.178164Z"
    },
    "papermill": {
     "duration": 19.101553,
     "end_time": "2024-12-16T14:07:52.180672",
     "exception": false,
     "start_time": "2024-12-16T14:07:33.079119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8a4e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:52.193377Z",
     "iopub.status.busy": "2024-12-16T14:07:52.192836Z",
     "iopub.status.idle": "2024-12-16T14:07:52.206398Z",
     "shell.execute_reply": "2024-12-16T14:07:52.205580Z"
    },
    "papermill": {
     "duration": 0.02156,
     "end_time": "2024-12-16T14:07:52.207902",
     "exception": false,
     "start_time": "2024-12-16T14:07:52.186342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class DepthwiseSeparableConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(DepthwiseSeparableConv1D, self).__init__()\n",
    "        self.depthwise = nn.Conv1d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   groups=in_channels, padding=kernel_size//2)\n",
    "        self.pointwise = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, num_classes,feedforward, max_len=5000,dropout=0):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "       #深度可分离卷积降维\n",
    "        self.conv1=DepthwiseSeparableConv1D(in_channels=1,out_channels=32,kernel_size = 11)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool= nn.MaxPool1d(2)#等价于nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2=DepthwiseSeparableConv1D(in_channels=32,out_channels=64,kernel_size = 21)\n",
    "        self.conv3=DepthwiseSeparableConv1D(in_channels=64,out_channels=128,kernel_size = 41)\n",
    "         # 线性投影层，将输入数据5000映射到 embed_dim 维度\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # 位置编码\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len)\n",
    "        \n",
    "        # Transformer 编码器层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 全局池化（或者可以选用 [CLS] token 表示）\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 最终分类层\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = x.permute(0, 2, 1)\n",
    "        #转置卷积forward\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        # print(x.shape)\n",
    "        # 输入 x 的形状：[batch_size, seq_len, input_dim]\n",
    "        x = self.embedding(x)  # 形状变为：[batch_size, seq_len, embed_dim]\n",
    "        x = self.pos_encoder(x)  # 添加位置编码\n",
    "        x = x.permute(1, 0, 2)  # Transformer 期望的输入形状：[seq_len, batch_size, embed_dim]\n",
    "        \n",
    "        # 通过 Transformer 编码器\n",
    "        x = self.transformer_encoder(x)  # 输出形状：[seq_len, batch_size, embed_dim]\n",
    "        x = x.permute(1, 2, 0)  # 调整形状为：[batch_size, embed_dim, seq_len]\n",
    "        \n",
    "        # 全局平均池化\n",
    "        x = self.global_avg_pool(x).squeeze(-1)  # 形状变为：[batch_size, embed_dim]\n",
    "        \n",
    "        # 全连接分类层\n",
    "        x = self.fc(x)  # 输出形状：[batch_size, num_classes]\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, embed_dim]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # 加上位置编码\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fbec7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:52.219448Z",
     "iopub.status.busy": "2024-12-16T14:07:52.219025Z",
     "iopub.status.idle": "2024-12-16T14:07:52.228223Z",
     "shell.execute_reply": "2024-12-16T14:07:52.227436Z"
    },
    "papermill": {
     "duration": 0.016839,
     "end_time": "2024-12-16T14:07:52.229912",
     "exception": false,
     "start_time": "2024-12-16T14:07:52.213073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from torch.optim import lr_scheduler\n",
    "config = Namespace(\n",
    "    project_name = \"two-transformer\",\n",
    "    file_path = \"alldata.csv\",\n",
    "    batch_size = 128,\n",
    "    dropout_p = 0.3,\n",
    "    lr = 0.0002,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 200,\n",
    "    ckpt_path = 'checkpoint',\n",
    "    num_workers=0,\n",
    "    name='two-1ddstn',\n",
    "    input_dim = 625,  # 转置卷积的输出维度\n",
    "    feedforward=128,\n",
    "    embed_dim = 64,  # 嵌入维度\n",
    "    num_heads = 4,  # 注意力头数\n",
    "    num_layers = 2,  # Transformer 编码器的层数\n",
    "    num_classes = 1,  # 分类类别数\n",
    "    max_len = 5000  # 输入的最大序列长度\n",
    ")\n",
    "\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5432aa26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:52.241625Z",
     "iopub.status.busy": "2024-12-16T14:07:52.241176Z",
     "iopub.status.idle": "2024-12-16T14:07:52.355821Z",
     "shell.execute_reply": "2024-12-16T14:07:52.354970Z"
    },
    "papermill": {
     "duration": 0.122352,
     "end_time": "2024-12-16T14:07:52.357569",
     "exception": false,
     "start_time": "2024-12-16T14:07:52.235217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from torchkeras import summary\n",
    "# a=torch.randn([2,1,5000])\n",
    "net = TimeSeriesTransformer(config.input_dim, config.embed_dim, config.num_heads, \n",
    "                            config.num_layers, config.num_classes,config.feedforward, config.max_len,config.dropout_p)\n",
    "# summary(net,input_data=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ff737b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:07:52.383826Z",
     "iopub.status.busy": "2024-12-16T14:07:52.383226Z",
     "iopub.status.idle": "2024-12-16T14:08:30.923571Z",
     "shell.execute_reply": "2024-12-16T14:08:30.922675Z"
    },
    "papermill": {
     "duration": 38.548598,
     "end_time": "2024-12-16T14:08:30.925589",
     "exception": false,
     "start_time": "2024-12-16T14:07:52.376991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-2]])##二分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#层归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dfdata = MyDataset(config.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c28ebc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:30.938892Z",
     "iopub.status.busy": "2024-12-16T14:08:30.938151Z",
     "iopub.status.idle": "2024-12-16T14:08:31.950612Z",
     "shell.execute_reply": "2024-12-16T14:08:31.949658Z"
    },
    "papermill": {
     "duration": 1.021433,
     "end_time": "2024-12-16T14:08:31.952882",
     "exception": false,
     "start_time": "2024-12-16T14:08:30.931449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#标准化\n",
    "bb= torch.mean(dfdata.xdata, dim=0)\n",
    "cc=torch.std(dfdata.xdata, dim=0)\n",
    "dfdata.xdata= (dfdata.xdata- bb) / cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4215a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:31.969827Z",
     "iopub.status.busy": "2024-12-16T14:08:31.969488Z",
     "iopub.status.idle": "2024-12-16T14:08:58.282181Z",
     "shell.execute_reply": "2024-12-16T14:08:58.281511Z"
    },
    "papermill": {
     "duration": 26.323343,
     "end_time": "2024-12-16T14:08:58.284197",
     "exception": false,
     "start_time": "2024-12-16T14:08:31.960854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset\n",
    "# dfdata.ydata=dfdata.ydata.squeeze(1)#\n",
    "# dfdata.ydata=dfdata.ydata.to(dtype=torch.int64) #使用交叉熵做损失函数时\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94732d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:58.296917Z",
     "iopub.status.busy": "2024-12-16T14:08:58.296670Z",
     "iopub.status.idle": "2024-12-16T14:08:58.301015Z",
     "shell.execute_reply": "2024-12-16T14:08:58.300321Z"
    },
    "papermill": {
     "duration": 0.012511,
     "end_time": "2024-12-16T14:08:58.302579",
     "exception": false,
     "start_time": "2024-12-16T14:08:58.290068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e653f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:58.314429Z",
     "iopub.status.busy": "2024-12-16T14:08:58.314156Z",
     "iopub.status.idle": "2024-12-16T14:08:58.324012Z",
     "shell.execute_reply": "2024-12-16T14:08:58.323410Z"
    },
    "papermill": {
     "duration": 0.01758,
     "end_time": "2024-12-16T14:08:58.325603",
     "exception": false,
     "start_time": "2024-12-16T14:08:58.308023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AUC(nn.Module):\n",
    "    'approximate AUC calculation for binary-classification task'\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        self.fp = nn.Parameter(torch.zeros(10001),requires_grad=False)\n",
    "        \n",
    "    def eval_auc(self,tp,fp):\n",
    "        tp_total = torch.sum(tp)\n",
    "        fp_total = torch.sum(fp)\n",
    "        length = len(tp)\n",
    "        tp_reverse = tp[range(length-1,-1,-1)]\n",
    "        tp_reverse_cum = torch.cumsum(tp_reverse,dim=0)-tp_reverse/2.0\n",
    "        fp_reverse = fp[range(length-1,-1,-1)]\n",
    "        \n",
    "        auc = torch.sum(torch.true_divide(tp_reverse_cum,tp_total)\n",
    "                        *torch.true_divide(fp_reverse,fp_total))\n",
    "        return auc\n",
    "        \n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        y_pred = (10000*torch.sigmoid(preds)).reshape(-1).type(torch.int)\n",
    "        y_true = targets.reshape(-1)\n",
    "        \n",
    "        tpi = self.tp-self.tp\n",
    "        fpi = self.fp-self.fp\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        for i,label in enumerate(y_true):\n",
    "            if label>=0.5:\n",
    "                tpi[y_pred[i]]+=1.0\n",
    "            else:\n",
    "                fpi[y_pred[i]]+=1.0\n",
    "        self.tp+=tpi\n",
    "        self.fp+=fpi\n",
    "        return self.eval_auc(tpi,fpi)\n",
    "          \n",
    "    def compute(self):\n",
    "        return self.eval_auc(self.tp,self.fp)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tp-=self.tp\n",
    "        self.fp-=self.fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d665104d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:58.337426Z",
     "iopub.status.busy": "2024-12-16T14:08:58.336952Z",
     "iopub.status.idle": "2024-12-16T14:08:58.352512Z",
     "shell.execute_reply": "2024-12-16T14:08:58.351523Z"
    },
    "papermill": {
     "duration": 0.023061,
     "end_time": "2024-12-16T14:08:58.354029",
     "exception": false,
     "start_time": "2024-12-16T14:08:58.330968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 5000])\n",
      "torch.Size([128, 1])\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "for features,labels in dl_train:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f3401d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:58.365598Z",
     "iopub.status.busy": "2024-12-16T14:08:58.365346Z",
     "iopub.status.idle": "2024-12-16T14:08:58.966981Z",
     "shell.execute_reply": "2024-12-16T14:08:58.965737Z"
    },
    "papermill": {
     "duration": 0.609559,
     "end_time": "2024-12-16T14:08:58.968949",
     "exception": false,
     "start_time": "2024-12-16T14:08:58.359390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Layer (type)                            Output Shape              Param #\n",
      "==========================================================================\n",
      "Conv1d-1                               [-1, 1, 5000]                   12\n",
      "Conv1d-2                              [-1, 32, 5000]                   64\n",
      "ReLU-3                                [-1, 32, 5000]                    0\n",
      "MaxPool1d-4                           [-1, 32, 2500]                    0\n",
      "Conv1d-5                              [-1, 32, 2500]                  704\n",
      "Conv1d-6                              [-1, 64, 2500]                2,112\n",
      "ReLU-7                                [-1, 64, 2500]                    0\n",
      "MaxPool1d-8                           [-1, 64, 1250]                    0\n",
      "Conv1d-9                              [-1, 64, 1250]                2,688\n",
      "Conv1d-10                            [-1, 128, 1250]                8,320\n",
      "ReLU-11                              [-1, 128, 1250]                    0\n",
      "MaxPool1d-12                          [-1, 128, 625]                    0\n",
      "Linear-13                              [-1, 128, 64]               40,064\n",
      "PositionalEncoding-14                  [-1, 128, 64]                    0\n",
      "MultiheadAttention-15                  [-1, 128, 64]               16,640\n",
      "Dropout-16                             [-1, 128, 64]                    0\n",
      "LayerNorm-17                           [-1, 128, 64]                  128\n",
      "Linear-18                             [-1, 128, 128]                8,320\n",
      "Dropout-19                            [-1, 128, 128]                    0\n",
      "Linear-20                              [-1, 128, 64]                8,256\n",
      "Dropout-21                             [-1, 128, 64]                    0\n",
      "LayerNorm-22                           [-1, 128, 64]                  128\n",
      "MultiheadAttention-23                  [-1, 128, 64]               16,640\n",
      "Dropout-24                             [-1, 128, 64]                    0\n",
      "LayerNorm-25                           [-1, 128, 64]                  128\n",
      "Linear-26                             [-1, 128, 128]                8,320\n",
      "Dropout-27                            [-1, 128, 128]                    0\n",
      "Linear-28                              [-1, 128, 64]                8,256\n",
      "Dropout-29                             [-1, 128, 64]                    0\n",
      "LayerNorm-30                           [-1, 128, 64]                  128\n",
      "AdaptiveAvgPool1d-31                     [-1, 64, 1]                    0\n",
      "Linear-32                                    [-1, 1]                   65\n",
      "==========================================================================\n",
      "Total params: 120,973\n",
      "Trainable params: 120,973\n",
      "Non-trainable params: 0\n",
      "--------------------------------------------------------------------------\n",
      "Input size (MB): 0.000076\n",
      "Forward/backward pass size (MB): 11.789619\n",
      "Params size (MB): 0.461475\n",
      "Estimated Total Size (MB): 12.251171\n",
      "--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'--------------------------------------------------------------------------\\nLayer (type)                            Output Shape              Param #\\n==========================================================================\\nConv1d-1                               [-1, 1, 5000]                   12\\nConv1d-2                              [-1, 32, 5000]                   64\\nReLU-3                                [-1, 32, 5000]                    0\\nMaxPool1d-4                           [-1, 32, 2500]                    0\\nConv1d-5                              [-1, 32, 2500]                  704\\nConv1d-6                              [-1, 64, 2500]                2,112\\nReLU-7                                [-1, 64, 2500]                    0\\nMaxPool1d-8                           [-1, 64, 1250]                    0\\nConv1d-9                              [-1, 64, 1250]                2,688\\nConv1d-10                            [-1, 128, 1250]                8,320\\nReLU-11                              [-1, 128, 1250]                    0\\nMaxPool1d-12                          [-1, 128, 625]                    0\\nLinear-13                              [-1, 128, 64]               40,064\\nPositionalEncoding-14                  [-1, 128, 64]                    0\\nMultiheadAttention-15                  [-1, 128, 64]               16,640\\nDropout-16                             [-1, 128, 64]                    0\\nLayerNorm-17                           [-1, 128, 64]                  128\\nLinear-18                             [-1, 128, 128]                8,320\\nDropout-19                            [-1, 128, 128]                    0\\nLinear-20                              [-1, 128, 64]                8,256\\nDropout-21                             [-1, 128, 64]                    0\\nLayerNorm-22                           [-1, 128, 64]                  128\\nMultiheadAttention-23                  [-1, 128, 64]               16,640\\nDropout-24                             [-1, 128, 64]                    0\\nLayerNorm-25                           [-1, 128, 64]                  128\\nLinear-26                             [-1, 128, 128]                8,320\\nDropout-27                            [-1, 128, 128]                    0\\nLinear-28                              [-1, 128, 64]                8,256\\nDropout-29                             [-1, 128, 64]                    0\\nLayerNorm-30                           [-1, 128, 64]                  128\\nAdaptiveAvgPool1d-31                     [-1, 64, 1]                    0\\nLinear-32                                    [-1, 1]                   65\\n==========================================================================\\nTotal params: 120,973\\nTrainable params: 120,973\\nNon-trainable params: 0\\n--------------------------------------------------------------------------\\nInput size (MB): 0.000076\\nForward/backward pass size (MB): 11.789619\\nParams size (MB): 0.461475\\nEstimated Total Size (MB): 12.251171\\n--------------------------------------------------------------------------'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchkeras import summary\n",
    "summary(net,input_data=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c977ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:08:58.982529Z",
     "iopub.status.busy": "2024-12-16T14:08:58.982152Z",
     "iopub.status.idle": "2024-12-16T14:09:00.079086Z",
     "shell.execute_reply": "2024-12-16T14:09:00.078232Z"
    },
    "papermill": {
     "duration": 1.105534,
     "end_time": "2024-12-16T14:09:00.080881",
     "exception": false,
     "start_time": "2024-12-16T14:08:58.975347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb \n",
    "wandb.login(key=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9eb4adc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:09:00.094505Z",
     "iopub.status.busy": "2024-12-16T14:09:00.094201Z",
     "iopub.status.idle": "2024-12-16T14:09:00.110344Z",
     "shell.execute_reply": "2024-12-16T14:09:00.109682Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.024587,
     "end_time": "2024-12-16T14:09:00.111942",
     "exception": false,
     "start_time": "2024-12-16T14:09:00.087355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainmodel VisMetri\n",
    "from torchkeras.utils import is_jupyter\n",
    "class VisMetric:\n",
    "    def __init__(self, figsize=(6, 4), save_path='history.png'):\n",
    "        \"\"\"Visualization callback for monitoring metrics\n",
    "\n",
    "        Args:\n",
    "            figsize (tuple, optional): Figure size. Defaults to (6, 4)\n",
    "            save_path (str, optional): Path to save the history plot. Defaults to 'history.png'\n",
    "        \"\"\"\n",
    "        self.figsize = (6, 4)\n",
    "        self.save_path = save_path\n",
    "        self.in_jupyter = is_jupyter()\n",
    "\n",
    "    def on_fit_start(self, model: 'KerasModel'):\n",
    "        \"\"\"Callback at the beginning of the training\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance.\n",
    "        \"\"\"\n",
    "        if not self.in_jupyter:\n",
    "            print('\\nView dynamic loss/metric plot: \\n' + os.path.abspath(self.save_path))\n",
    "        self.metric = model.monitor.replace('val_', '')\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        x_bounds = [0, min(10, model.epochs)]\n",
    "        title = f'best {model.monitor} = ?'\n",
    "        self.update_graph(model, title=title, x_bounds=x_bounds)\n",
    "\n",
    "    def on_train_epoch_end(self, model: 'KerasModel'):\n",
    "        \"\"\"Callback at the end of each training epoch\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def on_validation_epoch_end(self, model: \"KerasModel\"):\n",
    "        \"\"\"Callback at the end of each validation epoch\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        n = len(dfhistory)\n",
    "        x_bounds = [dfhistory['epoch'].min(), min(10 + (n // 10) * 10, model.epochs)]\n",
    "        title = self.get_title(model)\n",
    "        self.update_graph(model, title=title, x_bounds=x_bounds)\n",
    "\n",
    "    def on_fit_end(self, model: \"KerasModel\"):\n",
    "        \"\"\"Callback at the end of the entire training process\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        title = self.get_title(model)\n",
    "        self.update_graph(model, title=title)\n",
    "\n",
    "    def get_best_score(self, model: 'KerasModel'):\n",
    "        \"\"\"Get the best score and epoch.\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "\n",
    "        Returns:\n",
    "            tuple: Best epoch and best score\n",
    "        \"\"\"\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        arr_scores = dfhistory[model.monitor]\n",
    "        best_score = np.max(arr_scores) if model.mode == \"max\" else np.min(arr_scores)\n",
    "        best_epoch = dfhistory.loc[arr_scores == best_score, 'epoch'].tolist()[0]\n",
    "        return (best_epoch, best_score)\n",
    "\n",
    "    def get_title(self, model: 'KerasModel'):\n",
    "        \"\"\"Get the title for the plot\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "\n",
    "        Returns:\n",
    "            str: The title.\n",
    "        \"\"\"\n",
    "        best_epoch, best_score = self.get_best_score(model)\n",
    "        title = f'best {model.monitor}={best_score:.4f} (@epoch {best_epoch})'\n",
    "        return title\n",
    "\n",
    "    def update_graph(self, model: 'KerasModel', title=None, x_bounds=None, y_bounds=None):\n",
    "        \"\"\"Update the metric plot.\n",
    "\n",
    "        Args:\n",
    "            model (KerasModel): The KerasModel instance\n",
    "            title (str, optional): Plot title. Defaults to None\n",
    "            x_bounds (list, optional): x-axis bounds. Defaults to None\n",
    "            y_bounds (list, optional): y-axis bounds. Defaults to None\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        self.plt = plt\n",
    "        if not hasattr(self, 'graph_fig'):\n",
    "            self.graph_fig, self.graph_ax = plt.subplots(1, figsize=self.figsize)\n",
    "            if self.in_jupyter:\n",
    "                self.graph_out = display(self.graph_ax.figure, display_id=True)\n",
    "        self.graph_ax.clear()\n",
    "\n",
    "        dfhistory = pd.DataFrame(model.history)\n",
    "        epochs = dfhistory['epoch'] if 'epoch' in dfhistory.columns else []\n",
    "\n",
    "        m1 = \"train_\" + self.metric\n",
    "        if m1 in dfhistory.columns:\n",
    "            train_metrics = dfhistory[m1]\n",
    "            self.graph_ax.plot(epochs, train_metrics, 'bo--', label=m1, clip_on=False)\n",
    "\n",
    "        m2 = 'val_' + self.metric\n",
    "        if m2 in dfhistory.columns:\n",
    "            val_metrics = dfhistory[m2]\n",
    "            self.graph_ax.plot(epochs, val_metrics, 'c^-', label=m2, clip_on=False)\n",
    "\n",
    "        if self.metric in dfhistory.columns:\n",
    "            metric_values = dfhistory[self.metric]\n",
    "            self.graph_ax.plot(epochs, metric_values, 'c^-', label=self.metric, clip_on=False)\n",
    "\n",
    "        self.graph_ax.set_xlabel(\"epoch\")\n",
    "        self.graph_ax.set_ylabel(self.metric)\n",
    "        if title:\n",
    "            self.graph_ax.set_title(title)\n",
    "            if not self.in_jupyter and hasattr(model.EpochRunner, 'progress'):\n",
    "                model.EpochRunner.progress.comment_tail = title\n",
    "        if m1 in dfhistory.columns or m2 in dfhistory.columns or self.metric in dfhistory.columns:\n",
    "            self.graph_ax.legend(loc='best')\n",
    "\n",
    "        if len(epochs) > 0:\n",
    "            best_epoch, best_score = self.get_best_score(model)\n",
    "            self.graph_ax.plot(best_epoch, best_score, 'r*', markersize=15, clip_on=False)\n",
    "\n",
    "        if x_bounds is not None: self.graph_ax.set_xlim(*x_bounds)\n",
    "        if y_bounds is not None: self.graph_ax.set_ylim(*y_bounds)\n",
    "        if self.in_jupyter:\n",
    "            self.graph_out.update(self.graph_ax.figure)\n",
    "        self.graph_fig.savefig(self.save_path)\n",
    "        self.plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c971ca1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:09:00.125102Z",
     "iopub.status.busy": "2024-12-16T14:09:00.124844Z",
     "iopub.status.idle": "2024-12-16T14:09:00.163008Z",
     "shell.execute_reply": "2024-12-16T14:09:00.162135Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.046865,
     "end_time": "2024-12-16T14:09:00.164627",
     "exception": false,
     "start_time": "2024-12-16T14:09:00.117762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#kerasmodel\n",
    "import sys,datetime\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage=\"train\", metrics_dict=None,\n",
    "                 optimizer=None, lr_scheduler=None, **kwargs):\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.stage = net, loss_fn, metrics_dict, stage\n",
    "        self.optimizer, self.lr_scheduler = optimizer, lr_scheduler\n",
    "        self.kwargs = kwargs\n",
    "        self.accelerator = accelerator\n",
    "\n",
    "        # Set the network to training mode during the training stage, and evaluation mode otherwise\n",
    "        if self.stage == 'train':\n",
    "            self.net.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        features, labels = batch\n",
    "        # Compute loss\n",
    "        with self.accelerator.autocast():\n",
    "            preds = self.net(features)\n",
    "            loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        # Backward pass and optimization (only during training)\n",
    "        if self.stage == \"train\" and self.optimizer is not None:\n",
    "            self.accelerator.backward(loss)\n",
    "\n",
    "            # Clip gradients if synchronization is enabled\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Adjust learning rate if a scheduler is provided\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            # Zero gradients for the next iteration\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # Gather loss, predictions, and labels using the accelerator\n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        all_preds = self.accelerator.gather(preds)\n",
    "        all_labels = self.accelerator.gather(labels)\n",
    "\n",
    "        # Compute and gather additional metrics\n",
    "        step_losses = {self.stage + \"_loss\": all_loss.item()}\n",
    "        step_metrics = {self.stage + \"_\" + name: metric_fn(all_preds, all_labels).item()\n",
    "                        for name, metric_fn in self.metrics_dict.items()}\n",
    "\n",
    "        # Include learning rate in metrics if available\n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "                \n",
    "        return step_losses, step_metrics\n",
    "\n",
    "class EpochRunner:\n",
    "    def __init__(self, step_runner, quiet=False):\n",
    "        self.step_runner = step_runner\n",
    "        self.stage = step_runner.stage\n",
    "        self.accelerator = step_runner.accelerator\n",
    "        self.net = step_runner.net\n",
    "        self.quiet = quiet\n",
    "\n",
    "    def __call__(self, dataloader):\n",
    "        # Determine the size of the dataset\n",
    "        n = dataloader.size if hasattr(dataloader, 'size') else len(dataloader)\n",
    "\n",
    "        # Initialize tqdm progress bar\n",
    "        loop = tqdm(enumerate(dataloader, start=1),\n",
    "                    total=n,\n",
    "                    file=sys.stdout,\n",
    "                    disable=not self.accelerator.is_local_main_process or self.quiet,\n",
    "                    ncols=100\n",
    "                    )\n",
    "        epoch_losses = {}\n",
    "\n",
    "        for step, batch in loop:\n",
    "            # Perform a step with the provided StepRunner\n",
    "            with self.accelerator.accumulate(self.net):\n",
    "                step_losses, step_metrics = self.step_runner(batch)\n",
    "                step_log = dict(step_losses, **step_metrics)\n",
    "\n",
    "                # Accumulate step losses for computing epoch losses\n",
    "                for k, v in step_losses.items():\n",
    "                    epoch_losses[k] = epoch_losses.get(k, 0.0) + v\n",
    "\n",
    "                # Update progress bar during the epoch\n",
    "                if step < n:\n",
    "                    loop.set_postfix(**step_log)\n",
    "\n",
    "                    if hasattr(self, 'progress') and self.accelerator.is_local_main_process:\n",
    "                        post_log = dict(**{'i': step, 'n': n}, **step_log)\n",
    "                        self.progress.set_postfix(**post_log)\n",
    "\n",
    "                # Compute and display epoch-level metrics at the end of the epoch\n",
    "                elif step == n:\n",
    "                    epoch_metrics = step_metrics\n",
    "                    epoch_metrics.update({self.stage + \"_\" + name: metric_fn.compute().item()\n",
    "                                          for name, metric_fn in self.step_runner.metrics_dict.items()})\n",
    "                    epoch_losses = {k: v / step for k, v in epoch_losses.items()}\n",
    "                    epoch_log = dict(epoch_losses, **epoch_metrics)\n",
    "                    loop.set_postfix(**epoch_log)\n",
    "\n",
    "                    # Update progress bar if available\n",
    "                    if hasattr(self, 'progress') and self.accelerator.is_local_main_process:\n",
    "                        post_log = dict(**{'i': step, 'n': n}, **epoch_log)\n",
    "                        self.progress.set_postfix(**post_log)\n",
    "\n",
    "                    # Reset stateful metrics for the next epoch\n",
    "                    for name, metric_fn in self.step_runner.metrics_dict.items():\n",
    "                        metric_fn.reset()\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        return epoch_log\n",
    "\n",
    "class KerasModel(torch.nn.Module):\n",
    "    StepRunner, EpochRunner = StepRunner, EpochRunner\n",
    "\n",
    "    def __init__(self, net, loss_fn, metrics_dict=None, optimizer=None, lr_scheduler=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.net, self.loss_fn, self.metrics_dict = net, loss_fn, torch.nn.ModuleDict(metrics_dict)\n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.net.parameters(), lr=3e-4)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.kwargs = kwargs\n",
    "        self.from_scratch = True\n",
    "\n",
    "    def save_ckpt(self, ckpt_path=None, accelerator=None):\n",
    "        accelerator = accelerator if accelerator is not None else self.accelerator\n",
    "        net_dict = accelerator.get_state_dict(self.net)\n",
    "        accelerator.save(net_dict, ckpt_path if ckpt_path is not None else self.ckpt_path)\n",
    "\n",
    "    def load_ckpt(self, ckpt_path=None):\n",
    "        self.net.load_state_dict(torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n",
    "                                            map_location='cpu'))\n",
    "        self.from_scratch = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net.forward(x)\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint',\n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None,\n",
    "            plot=True, wandb=False, quiet=None,\n",
    "            mixed_precision='no', cpu=False, gradient_accumulation_steps=1):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        Args:\n",
    "            train_data: Training data\n",
    "            val_data: Validation data\n",
    "            epochs: Number of training epochs\n",
    "            ckpt_path: Path to save model checkpoints\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            monitor: Metric to monitor for early stopping\n",
    "            mode: 'min' for minimizing the monitor metric, 'max' for maximizing\n",
    "            callbacks: List of callback functions\n",
    "            plot: Whether to plot training progress\n",
    "            wandb: Whether to use WandB for logging\n",
    "            quiet: Whether to suppress training progress logs\n",
    "            mixed_precision: Mixed precision training ('no', 'O1', 'O2', 'O3')\n",
    "            cpu: Use CPU for training\n",
    "            gradient_accumulation_steps: Number of steps to accumulate gradients before optimizer step\n",
    "\n",
    "        Returns:\n",
    "            DataFrame containing training history.\n",
    "        \"\"\"\n",
    "        self.__dict__.update(locals())\n",
    "        from accelerate import Accelerator\n",
    "        from torchkeras.utils import colorful, is_jupyter\n",
    "\n",
    "        self.accelerator = Accelerator(mixed_precision=mixed_precision, cpu=cpu,\n",
    "                                       gradient_accumulation_steps=gradient_accumulation_steps)\n",
    "\n",
    "        device = str(self.accelerator.device)\n",
    "        device_type = '🐌' if 'cpu' in device else ('⚡️' if 'cuda' in device else '🚀')\n",
    "        self.accelerator.print(\n",
    "            colorful(\"<<<<<< \" + device_type + \" \" + device + \" is used >>>>>>\"))\n",
    "\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.optimizer, self.lr_scheduler = self.accelerator.prepare(\n",
    "            self.net, self.loss_fn, self.metrics_dict, self.optimizer, self.lr_scheduler)\n",
    "\n",
    "        for key in self.kwargs:\n",
    "            self.kwargs[key] = self.accelerator.prepare(self.kwargs[key])\n",
    "\n",
    "        train_dataloader, val_dataloader = self.accelerator.prepare(train_data, val_data)\n",
    "        train_dataloader.size = train_data.size if hasattr(train_data, 'size') else len(train_data)\n",
    "        train_dataloader.size = min(train_dataloader.size, len(train_dataloader))\n",
    "\n",
    "        if val_data:\n",
    "            val_dataloader.size = val_data.size if hasattr(val_data, 'size') else len(val_data)\n",
    "            val_dataloader.size = min(val_dataloader.size, len(val_dataloader))\n",
    "\n",
    "        self.history = {}\n",
    "        callbacks = callbacks if callbacks is not None else []\n",
    "\n",
    "        if bool(plot):\n",
    "            from torchkeras.kerascallbacks import VisProgress\n",
    "            callbacks = [VisMetric(), VisProgress()] + callbacks\n",
    "\n",
    "        if wandb != False:\n",
    "            from torchkeras.kerascallbacks import WandbCallback\n",
    "            project = wandb if isinstance(wandb, str) else 'torchkeras'\n",
    "            callbacks.append(WandbCallback(project=project))\n",
    "\n",
    "        self.callbacks = [self.accelerator.prepare(x) for x in callbacks]\n",
    "\n",
    "        if self.accelerator.is_local_main_process:\n",
    "            [cb.on_fit_start(model=self) for cb in self.callbacks if hasattr(cb, 'on_fit_start')]\n",
    "\n",
    "        start_epoch = 1 if self.from_scratch else 0\n",
    "\n",
    "        if bool(plot) or quiet is None:\n",
    "            quiet = True\n",
    "\n",
    "        quiet_fn = (lambda epoch: quiet) if isinstance(quiet, bool) else (\n",
    "            (lambda epoch: epoch > quiet) if isinstance(quiet, int) else quiet)\n",
    "\n",
    "        for epoch in range(start_epoch, epochs + 1):\n",
    "            should_quiet = quiet_fn(epoch)\n",
    "\n",
    "            if not should_quiet:\n",
    "                nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                self.accelerator.print(\"\\n\" + \"==========\" * 8 + \"%s\" % nowtime)\n",
    "                self.accelerator.print(\"Epoch {0} / {1}\".format(epoch, epochs) + \"\\n\")\n",
    "\n",
    "            # 1，train -------------------------------------------------\n",
    "            train_step_runner = self.StepRunner(\n",
    "                net=self.net,\n",
    "                loss_fn=self.loss_fn,\n",
    "                accelerator=self.accelerator,\n",
    "                stage=\"train\",\n",
    "                metrics_dict=deepcopy(self.metrics_dict),\n",
    "                optimizer=self.optimizer if epoch > 0 else None,\n",
    "                lr_scheduler=self.lr_scheduler if epoch > 0 else None,\n",
    "                **self.kwargs\n",
    "            )\n",
    "\n",
    "            train_epoch_runner = self.EpochRunner(train_step_runner, should_quiet)\n",
    "            train_metrics = {'epoch': epoch}\n",
    "            train_metrics.update(train_epoch_runner(train_dataloader))\n",
    "\n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            if self.accelerator.is_local_main_process:\n",
    "                [cb.on_train_epoch_end(model=self) for cb in self.callbacks\n",
    "                 if hasattr(cb, 'on_train_epoch_end')]\n",
    "            # 2，validate -------------------------------------------------\n",
    "            if val_dataloader is not None:\n",
    "                val_step_runner = self.StepRunner(\n",
    "                    net = self.net,\n",
    "                    loss_fn = self.loss_fn,\n",
    "                    accelerator = self.accelerator,\n",
    "                    stage=\"val\",\n",
    "                    metrics_dict= deepcopy(self.metrics_dict),\n",
    "                    **self.kwargs\n",
    "                )\n",
    "                val_epoch_runner = self.EpochRunner(val_step_runner,should_quiet)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_dataloader)\n",
    "\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "                \n",
    "            if self.accelerator.is_local_main_process:\n",
    "                [cb.on_validation_epoch_end(model = self) for cb in self.callbacks \n",
    "                 if hasattr(cb,'on_validation_epoch_end')]\n",
    "\n",
    "            # 3，early-stopping -------------------------------------------------\n",
    "            self.accelerator.wait_for_everyone()\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "\n",
    "            if best_score_idx==len(arr_scores)-1 and self.accelerator.is_local_main_process:\n",
    "                self.save_ckpt(ckpt_path,accelerator = self.accelerator)\n",
    "                if not should_quiet:\n",
    "                    self.accelerator.print(colorful(\"<<<<<< reach best {0} : {1} >>>>>>\".format(\n",
    "                        monitor,arr_scores[best_score_idx])))\n",
    "\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                break\n",
    "                \n",
    "        if self.accelerator.is_local_main_process:   \n",
    "            dfhistory = pd.DataFrame(self.history)\n",
    "            [cb.on_fit_end(model = self) for cb in self.callbacks \n",
    "                 if hasattr(cb,'on_fit_end')]\n",
    "            if epoch<epochs:\n",
    "                self.accelerator.print(colorful(\n",
    "                        \"<<<<<< {} without improvement in {} epoch,\"\"early stopping >>>>>> \\n\"\n",
    "                    ).format(monitor,patience))\n",
    "            self.net = self.accelerator.unwrap_model(self.net)\n",
    "            self.net.cpu()\n",
    "            self.load_ckpt(ckpt_path)\n",
    "            return dfhistory\n",
    "        \n",
    "    def evaluate(self, val_data, quiet=False):\n",
    "        \"\"\"\n",
    "        Evaluate the model on validation data\n",
    "\n",
    "        Args:\n",
    "            val_data: Validation data\n",
    "            quiet: Whether to suppress evaluation progress logs\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        # Ensure accelerator is available or create a new one\n",
    "        from accelerate import Accelerator\n",
    "        accelerator = Accelerator() if not hasattr(self, 'accelerator') else self.accelerator\n",
    "\n",
    "        # Prepare model, loss function, and metrics for evaluation\n",
    "        self.net, self.loss_fn, self.metrics_dict = accelerator.prepare(\n",
    "            self.net, self.loss_fn, self.metrics_dict)\n",
    "\n",
    "        val_data = accelerator.prepare(val_data)\n",
    "\n",
    "        # Initialize StepRunner for validation\n",
    "        val_step_runner = self.StepRunner(net=self.net, stage=\"val\",\n",
    "                                          loss_fn=self.loss_fn, metrics_dict=deepcopy(self.metrics_dict),\n",
    "                                          accelerator=accelerator)\n",
    "\n",
    "        # Initialize EpochRunner for validation\n",
    "        val_epoch_runner = self.EpochRunner(val_step_runner, quiet=quiet)\n",
    "\n",
    "        # Evaluate on validation data without gradient computation\n",
    "        with torch.no_grad():\n",
    "            val_metrics = val_epoch_runner(val_data)\n",
    "\n",
    "        return val_metrics\n",
    "    \n",
    "    def fit_ddp(self, num_processes, train_data,\n",
    "                val_data=None, epochs=10, ckpt_path='checkpoint',\n",
    "                patience=5, monitor=\"val_loss\", mode=\"min\", callbacks=None,\n",
    "                plot=True, wandb=False, quiet=None,\n",
    "                mixed_precision='no', cpu=False, gradient_accumulation_steps=1):\n",
    "        \"\"\"\n",
    "        Distributed Data Parallel (DDP) training for the model.\n",
    "\n",
    "        Args:\n",
    "            num_processes: Number of processes for DDP\n",
    "            train_data: Training data\n",
    "            val_data: Validation data\n",
    "            epochs: Number of training epochs\n",
    "            ckpt_path: Path to save model checkpoints\n",
    "            patience: Number of epochs with no improvement after which training will be stopped\n",
    "            monitor: Metric to monitor for early stopping\n",
    "            mode: 'min' for minimizing the monitor metric, 'max' for maximizing\n",
    "            callbacks: List of callback functions\n",
    "            plot: Whether to plot training progress\n",
    "            wandb: Whether to use WandB for logging\n",
    "            quiet: Whether to suppress training progress logs\n",
    "            mixed_precision: Mixed precision training ('no', 'O1', 'O2', 'O3')\n",
    "            cpu: Use CPU for training\n",
    "            gradient_accumulation_steps: Number of steps to accumulate gradients before optimizer step\n",
    "        \"\"\"\n",
    "        # Import notebook_launcher from accelerate\n",
    "        from accelerate import notebook_launcher\n",
    "\n",
    "        # Create a tuple of arguments for the fit method\n",
    "        args = (train_data, val_data, epochs, ckpt_path, patience, monitor, mode,\n",
    "                callbacks, plot, wandb, quiet, mixed_precision, cpu, gradient_accumulation_steps)\n",
    "\n",
    "        # Launch the fit method using notebook_launcher\n",
    "        notebook_launcher(self.fit, args, num_processes=num_processes)\n",
    "    \n",
    "    def evaluate_ddp(self, num_processes, val_data, quiet=False):\n",
    "        \"\"\"\n",
    "        Distributed Data Parallel (DDP) evaluation for the model\n",
    "\n",
    "        Args:\n",
    "            num_processes: Number of processes for DDP\n",
    "            val_data: Validation data.\n",
    "            quiet: Whether to suppress evaluation progress logs\n",
    "\n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        # Import notebook_launcher from accelerate\n",
    "        from accelerate import notebook_launcher\n",
    "\n",
    "        # Create a tuple of arguments for the evaluate method\n",
    "        args = (val_data, quiet)\n",
    "\n",
    "        # Launch the evaluate method using notebook_launcher\n",
    "        notebook_launcher(self.evaluate, args, num_processes=num_processes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee009e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:09:00.177446Z",
     "iopub.status.busy": "2024-12-16T14:09:00.177173Z",
     "iopub.status.idle": "2024-12-16T14:09:00.545429Z",
     "shell.execute_reply": "2024-12-16T14:09:00.544740Z"
    },
    "papermill": {
     "duration": 0.376682,
     "end_time": "2024-12-16T14:09:00.547316",
     "exception": false,
     "start_time": "2024-12-16T14:09:00.170634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchkeras import KerasModel\n",
    "from torchkeras.metrics import Accuracy\n",
    "from torchkeras.metrics import Precision\n",
    "from torchkeras.metrics import Recall\n",
    "\n",
    "from torchkeras.kerascallbacks import WandbCallback\n",
    "# net2 = create_net()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr=config.lr)\n",
    "metric_dict = {\"acc\":Accuracy(),\"pre\":Precision(),\"recall\":Recall(),\"auc\":AUC()}\n",
    "model = KerasModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metric_dict,\n",
    "                   optimizer = optimizer\n",
    "                  )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70220883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:09:00.560755Z",
     "iopub.status.busy": "2024-12-16T14:09:00.560505Z",
     "iopub.status.idle": "2024-12-16T14:09:00.564301Z",
     "shell.execute_reply": "2024-12-16T14:09:00.563540Z"
    },
    "papermill": {
     "duration": 0.012199,
     "end_time": "2024-12-16T14:09:00.565903",
     "exception": false,
     "start_time": "2024-12-16T14:09:00.553704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchkeras.kerascallbacks import WandbCallback\n",
    "wandb_cb = WandbCallback(project=config.project_name,\n",
    "                         config=config,\n",
    "                         name=None,\n",
    "                         save_code=True,\n",
    "                         save_ckpt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "242c04c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T14:09:00.578523Z",
     "iopub.status.busy": "2024-12-16T14:09:00.578255Z",
     "iopub.status.idle": "2024-12-16T14:36:26.269427Z",
     "shell.execute_reply": "2024-12-16T14:36:26.268420Z"
    },
    "papermill": {
     "duration": 1645.699495,
     "end_time": "2024-12-16T14:36:26.271217",
     "exception": false,
     "start_time": "2024-12-16T14:09:00.571722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* background: */\n",
       "    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n",
       "    progress {background-color: #CDCDCD;}\n",
       "\n",
       "    /* value: */\n",
       "    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n",
       "    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n",
       "    progress {color: #00BFFF ;}\n",
       "\n",
       "    /* optional */\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #000000;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='127' class='progress-bar-interrupted' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      63.50% [127/200] [27:22<15:43]\n",
       "      <br>\n",
       "      ████████████████████100.00% [38/38] [val_loss=0.1396, val_acc=0.9751, val_pre=0.9875, val_recall=0.9622, val_auc=0.9909]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mviolet6418\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241216_140901-2a1b6a75\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m2024-12-16 14:09:00\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/violet6418/twotransformerbase\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/violet6418/twotransformerbase/runs/2a1b6a75\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: best_val_acc ▁▁▁▅▆▇▇▇▇▇▇▇████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc ▁▁▃▅▇▇▇▇▇▇▇█████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_auc ▁▆▇▇▇▇██████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss █▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_pre ▁▁▁▂▆▇▇▇▇▇▇▇████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_recall ▂▁▃▃▅▅▆▆▇▇▇▇▇▇▇▇████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc ▁▂▇▇▇▇▇▇▇███████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_auc ▁▁▁▅▇███████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █████▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_pre  ▁▃▇▇▇█▇▇▇█▇█▇██████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_recall ▁█▃▆▆▇▆▇▇▇▇▇▇██▇█████▇████▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_score 0.97786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: best_val_acc 0.97786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch 127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           lr 0.0002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_acc 0.98825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_auc 0.99899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   train_loss 0.0351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_pre 0.99071\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_recall 0.98588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_acc 0.97515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_auc 0.99093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss 0.1396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_pre 0.98751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_recall 0.96222\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33m2024-12-16 14:09:00\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/violet6418/twotransformerbase/runs/2a1b6a75\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/violet6418/twotransformerbase\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241216_140901-2a1b6a75/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< val_acc without improvement in 15 epoch,early stopping >>>>>> \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2172050041.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(ckpt_path if ckpt_path is not None else self.ckpt_path,\n"
     ]
    }
   ],
   "source": [
    "dfhistory = model.fit(\n",
    "      train_data=dl_train,\n",
    "      val_data=dl_val,\n",
    "      epochs=config.epochs,\n",
    "      ckpt_path='checkpoint',\n",
    "      patience=15,\n",
    "      monitor='val_acc',\n",
    "      mode='max',\n",
    "      callbacks = [wandb_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82447f",
   "metadata": {
    "papermill": {
     "duration": 0.008104,
     "end_time": "2024-12-16T14:36:26.287532",
     "exception": false,
     "start_time": "2024-12-16T14:36:26.279428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5940593,
     "sourceId": 9711824,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1771.137252,
   "end_time": "2024-12-16T14:36:29.348895",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T14:06:58.211643",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

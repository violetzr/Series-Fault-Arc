{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad4bc19",
   "metadata": {},
   "source": [
    "# 1准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from torch.optim import lr_scheduler\n",
    "config = Namespace(\n",
    "    file_path =\"../alldata3.csv\",\n",
    "    batch_size = 128,\n",
    "    dropout_p = 0.2,\n",
    "    lr = 0.0001,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 200,\n",
    "    ckpt_path = 'checkpoint',\n",
    "    num_workers=0,\n",
    "    name='transCNNtransformer',\n",
    "    input_dim = 625,  # 转置卷积的输出维度\n",
    "    embed_dim = 256,  # 嵌入维度\n",
    "    num_heads = 8,  # 注意力头数\n",
    "    num_layers = 2,  # Transformer 编码器的层数\n",
    "    num_classes = 14,  # 分类类别数\n",
    "    max_len = 5000  # 输入的最大序列长度\n",
    ")\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d84fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-1]])##多分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#层归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dfdata = MyDataset(config.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "dfdata.ydata=dfdata.ydata.squeeze(1)#\n",
    "dfdata.ydata=dfdata.ydata.to(dtype=torch.int64) #使用交叉熵做损失函数时\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51108dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(dftrain) = \",len(dftrain_raw))\n",
    "print(\"len(dfval) = \",len(dfval_raw))\n",
    "print(\"len(dftest) = \",len(dftest_raw))\n",
    "print(dfdata.xdata.shape)\n",
    "print(dfdata.ydata.shape)\n",
    "print(type(dfdata.ydata[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_val:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows操作系统\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签 \n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7963f8",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "class DepthwiseSeparableConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(DepthwiseSeparableConv1D, self).__init__()\n",
    "        self.depthwise = nn.Conv1d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   groups=in_channels, padding=kernel_size//2)\n",
    "        self.pointwise = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, num_classes, max_len=5000):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "       #深度可分离卷积降维\n",
    "        self.conv1=DepthwiseSeparableConv1D(in_channels=1,out_channels=32,kernel_size = 11)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool= nn.MaxPool1d(2)#等价于nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2=DepthwiseSeparableConv1D(in_channels=32,out_channels=64,kernel_size = 21)\n",
    "        self.conv3=DepthwiseSeparableConv1D(in_channels=64,out_channels=128,kernel_size = 41)\n",
    "         # 线性投影层，将输入数据5000映射到 embed_dim 维度\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # 位置编码\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len)\n",
    "        \n",
    "        # Transformer 编码器层\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads,\n",
    "                                                   dim_feedforward=256, dropout=0.2)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        # 全局池化（或者可以选用 [CLS] token 表示）\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # 最终分类层\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x = x.permute(0, 2, 1)\n",
    "        #转置卷积forward\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        # print(x.shape)\n",
    "        # 输入 x 的形状：[batch_size, seq_len, input_dim]\n",
    "        x = self.embedding(x)  # 形状变为：[batch_size, seq_len, embed_dim]\n",
    "        x = self.pos_encoder(x)  # 添加位置编码\n",
    "        x = x.permute(1, 0, 2)  # Transformer 期望的输入形状：[seq_len, batch_size, embed_dim]\n",
    "        \n",
    "        # 通过 Transformer 编码器\n",
    "        x = self.transformer_encoder(x)  # 输出形状：[seq_len, batch_size, embed_dim]\n",
    "        x = x.permute(1, 2, 0)  # 调整形状为：[batch_size, embed_dim, seq_len]\n",
    "        \n",
    "        # 全局平均池化\n",
    "        x = self.global_avg_pool(x).squeeze(-1)  # 形状变为：[batch_size, embed_dim]\n",
    "        \n",
    "        # 全连接分类层\n",
    "        x = self.fc(x)  # 输出形状：[batch_size, num_classes]\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, embed_dim]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]  # 加上位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiAccuracy(nn.Module):\n",
    "    \"\"\"Accuracy for multi-classification task.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Accuracy module.\"\"\"\n",
    "        super().__init__()\n",
    "        # Counters for correct and total predictions\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "         return self.correct.float() / self.total \n",
    "\n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "net = TimeSeriesTransformer(config.input_dim, config.embed_dim, config.num_heads, \n",
    "                            config.num_layers, config.num_classes, config.max_len)\n",
    "summary(net,input_data=features);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26827df",
   "metadata": {},
   "source": [
    "# 验证集参数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9964c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bde50b",
   "metadata": {},
   "source": [
    "support：当前行的类别在测试数据中的样本总量，如上表就是，在class 0 类别在测试集中总数量为1；<br>\n",
    "precision：精度=正确预测的个数(TP)/被预测正确的个数(TP+FP)；人话也就是模型预测的结果中有多少是预测正确的<br>\n",
    "ecall:召回率=正确预测的个数(TP)/预测个数(TP+FN)；人话也就是某个类别测试集中的总量，有多少样本预测正确了；<br>\n",
    "f1-score:F1 = 2*精度*召回率/(精度+召回率)<br>\n",
    "micro avg：计算所有数据下的指标值，假设全部数据 5 个样本中有 3 个预测正确，所以 micro avg 为 3/5=0.6<br>\n",
    "macro avg：每个类别评估指标未加权的平均值，比如准确率的 macro avg，(0.50+0.00+1.00)/3=0.5<br>\n",
    "weighted avg：加权平均，就是测试集中样本量大的，给他设置的权重大点；比如第一个值的计算方法，(0.50*1 + 0.0*1 + 1.0*3)/5 = 0.70。更好点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfe55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    "net2 = TimeSeriesTransformer(config.input_dim, config.embed_dim, config.num_heads, \n",
    "                            config.num_layers, config.num_classes, config.max_len) \n",
    "net2.load_state_dict(torch.load('checkpoint_multi-transformer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f40fda",
   "metadata": {},
   "source": [
    "# 评估矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce4944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn.metrics import classification_report\n",
    "net2 = net2.cpu()\n",
    "net2.eval()\n",
    "preds = []\n",
    "believer=[]\n",
    "ytrue=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dl_test):\n",
    "        inputs,labels=batch\n",
    "#         print(inputs.shape)\n",
    "#         print(labels.shape)\n",
    "        \n",
    "        x=net2(inputs)\n",
    "#         print(x.shape)\n",
    "#         be= F.softmax(x, dim=1)\n",
    "        believer.extend(x.tolist())\n",
    "        preds.extend(x.argmax(dim=-1).tolist())\n",
    "        ytrue.extend(labels.tolist())\n",
    "    pprint(len(preds)) \n",
    "    pprint(len(ytrue))\n",
    "    pprint(len(believer))\n",
    "#     pprint(preds) \n",
    "#     pprint(yhat)\n",
    "reportt=classification_report(ytrue,preds)\n",
    "print(reportt)#打印每个类别的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(ytrue,preds)\n",
    "# 将混淆矩阵转换为DataFrame\n",
    "df_cm = pd.DataFrame(cm, index=['True {}'.format(i) for i in range(cm.shape[0])],columns=['Predicted {}'.format(i) for i in range(cm.shape[1])])\n",
    "# pprint(df_cm)\n",
    "# pprint(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e91233",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "ax=plt.matshow(cm , cmap=plt.cm.Blues,fignum=1, aspect='auto') \n",
    "cbar=plt.colorbar(ax, fraction=0.05, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "for i in range(len(cm )): \n",
    "    for j in range(len(cm )):\n",
    "        plt.annotate(cm [i,j], xy=(i, j), horizontalalignment='center', verticalalignment='center',fontsize=20)\n",
    "plt.ylabel('真实值标签',fontsize=40)\n",
    "plt.xlabel('预测值标签',fontsize=40) \n",
    "plt.tick_params(axis='both', labelsize=30)\n",
    "plt.savefig('multi-混淆.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97201e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PR\n",
    "import math\n",
    "result_matrix = [[math.exp(element) for element in row] for row in believer] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8477bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1二分类标注\n",
    "# df = pd.DataFrame()\n",
    "tempp=np.array(ytrue)\n",
    "y_test =(tempp==0)\n",
    "#2二分类预测置信度\n",
    "tempr=np.array(result_matrix)\n",
    "y_score = tempr[:,0]\n",
    "y_score\n",
    "#3计算ap\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "AP = average_precision_score(y_test, y_score, average='weighted')\n",
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4计算auc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c18a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "import random\n",
    "random.seed(124)\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan', 'black', 'indianred', 'brown', 'firebrick', 'maroon', 'darkred', 'red', 'sienna', 'chocolate', 'yellow', 'olivedrab', 'yellowgreen', 'darkolivegreen', 'forestgreen', 'limegreen', 'darkgreen', 'green', 'lime', 'seagreen', 'mediumseagreen', 'darkslategray', 'darkslategrey', 'teal', 'darkcyan', 'dodgerblue', 'navy', 'darkblue', 'mediumblue', 'blue', 'slateblue', 'darkslateblue', 'mediumslateblue', 'mediumpurple', 'rebeccapurple', 'blueviolet', 'indigo', 'darkorchid', 'darkviolet', 'mediumorchid', 'purple', 'darkmagenta', 'fuchsia', 'magenta', 'orchid', 'mediumvioletred', 'deeppink', 'hotpink']\n",
    "markers = [\".\",\",\",\"o\",\"v\",\"^\",\"<\",\">\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "linestyle = ['--', '-.', '-']\n",
    "def get_line_arg():\n",
    "    '''\n",
    "    随机产生一种绘图线型\n",
    "    '''\n",
    "    line_arg = {}\n",
    "    line_arg['color'] = random.choice(colors)\n",
    "    # line_arg['marker'] = random.choice(markers)\n",
    "    line_arg['linestyle'] = random.choice(linestyle)\n",
    "    line_arg['linewidth'] = random.randint(1, 4)\n",
    "    # line_arg['markersize'] = random.randint(3, 5)\n",
    "    return line_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_line_arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "# plt.plot([0, 1], [0, 1],ls=\"--\", c='.3', linewidth=3, label='随机模型')\n",
    "plt.xlabel('召回率',fontsize=25)\n",
    "plt.ylabel('精确率',fontsize=25)\n",
    "plt.rcParams['font.size'] = 22\n",
    "# plt.grid(True)\n",
    "\n",
    "ap_list = []\n",
    "for each_class in classes:\n",
    "    y_test = list((tempp == each_class))\n",
    "#     print(len(y_test),each_class)\n",
    "    y_score = list(tempr[:,each_class])\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    AP = average_precision_score(y_test, y_score, average='weighted')\n",
    "    plt.plot(recall, precision, **get_line_arg(), label='label:'+str(each_class))\n",
    "    plt.legend()\n",
    "    ap_list.append(AP)\n",
    "\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.savefig('multi-各类别PR曲线2.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "# plt.plot([0, 1], [0, 1],ls=\"--\", c='.3', linewidth=3, label='随机模型')\n",
    "plt.xlabel('假正率')\n",
    "plt.ylabel('真正率')\n",
    "plt.rcParams['font.size'] = 22\n",
    "# plt.grid(True)\n",
    "\n",
    "auc_list = []\n",
    "for each_class in classes:\n",
    "    y_test = list((tempp == each_class))\n",
    "    y_score = list(tempr[:,each_class])\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "    plt.plot(fpr, tpr, **get_line_arg(), label='label:'+str(each_class))\n",
    "    plt.legend()\n",
    "    auc_list.append(auc(fpr, tpr))\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.savefig('multi-各类别ROC曲线.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ded11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10757e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存1\n",
    "report=classification_report(ytrue,preds,target_names=classes, output_dict=True)\n",
    "del report['accuracy']\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 ap值 的 宏平均 和 加权平均\n",
    "macro_avg_auc = np.mean(ap_list)\n",
    "# print(len(ap_list))\n",
    "weighted_avg_auc = sum(ap_list * df_report.iloc[:-2]['support'] / len(ytrue))\n",
    "ap_list.append(macro_avg_auc)\n",
    "ap_list.append(weighted_avg_auc)\n",
    "# print(len(ap_list))\n",
    "df_report['AP'] = ap_list\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbba43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 计算 AUC值 的 宏平均 和 加权平均\n",
    "macro_avg_auc = np.mean(auc_list)\n",
    "weighted_avg_auc = sum(auc_list * df_report.iloc[:-2]['support'] / len(ytrue))\n",
    "auc_list.append(macro_avg_auc)\n",
    "auc_list.append(weighted_avg_auc)\n",
    "df_report['AUC'] = auc_list\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_csv('各类别准确率评估指标.csv', index_label='类别')\n",
    "# df_report.to_csv('各类别准确率评估指标.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e9d9f8",
   "metadata": {},
   "source": [
    "# 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810957e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(ytrue,preds)\n",
    "# 将混淆矩阵转换为DataFrame\n",
    "df_cm = pd.DataFrame(cm, index=['True {}'.format(i) for i in range(cm.shape[0])],columns=['Predicted {}'.format(i) for i in range(cm.shape[1])])\n",
    "pprint(df_cm)\n",
    "pprint(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(ytrue,preds)\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d628fd5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d04149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1!!!!!!!!!!!!!使用seaborn绘制混淆矩阵、seaborn版本过老\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e629dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2# 使用matplotlib\n",
    "plt.figure(figsize=(20, 20))\n",
    "ax=plt.matshow(cm , cmap=plt.cm.Blues,fignum=1, aspect='auto') \n",
    "cbar=plt.colorbar(ax, fraction=0.05, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "for i in range(len(cm )): \n",
    "    for j in range(len(cm )):\n",
    "        plt.annotate(cm [i,j], xy=(i, j), horizontalalignment='center', verticalalignment='center',fontsize=20)\n",
    "plt.ylabel('True label',fontsize=40)\n",
    "plt.xlabel('Predicted label',fontsize=40) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

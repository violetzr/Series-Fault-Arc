{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad4bc19",
   "metadata": {},
   "source": [
    "# 1准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from torch.optim import lr_scheduler\n",
    "config = Namespace(\n",
    "    file_path =\"../alldata3.csv\",\n",
    "    batch_size = 64,\n",
    "    # dropout_p = 0.2,\n",
    "    lr = 1e-3,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 200,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d84fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-1]])##多分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#层归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dfdata = MyDataset(config.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "dfdata.ydata=dfdata.ydata.squeeze(1)#\n",
    "dfdata.ydata=dfdata.ydata.to(dtype=torch.int64) #使用交叉熵做损失函数时\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51108dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(dftrain) = \",len(dftrain_raw))\n",
    "print(\"len(dfval) = \",len(dfval_raw))\n",
    "print(\"len(dftest) = \",len(dftest_raw))\n",
    "print(dfdata.xdata.shape)\n",
    "print(dfdata.ydata.shape)\n",
    "print(type(dfdata.ydata[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_val:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows操作系统\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签 \n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7963f8",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, module='torch.nn')\n",
    "\n",
    "class Inception(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters):\n",
    "        super(Inception, self).__init__()\n",
    "#         瓶颈层用于减少维度或保持维度不变以便进行后续操作\n",
    "# 当stride=1时，padding='SAME'意味着卷积后的输出与输入size保持一致\n",
    "        self.bottleneck1 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "# 不同的卷积运算与池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果将获得更好的图像表征。        \n",
    "        self.conv20 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=20,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=5,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv40 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=40,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=5,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.conv60 = torch.nn.Conv1d(\n",
    "            in_channels=filters,\n",
    "            out_channels=filters,\n",
    "            kernel_size=60,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            dilation=5,\n",
    "            bias=False\n",
    "        )\n",
    "        \n",
    "        self.max_pool = torch.nn.MaxPool1d(\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        \n",
    "        self.bottleneck2 = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "#         当input的维度为（N, C）时，BN将对C维归一化；当input的维度为(N, C, L) 时，归一化的维度同样为C维。\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.bottleneck1(x)\n",
    "        x1 = self.conv20(x0)\n",
    "        x2 = self.conv40(x0)\n",
    "        x3 = self.conv60(x0)\n",
    "        x4 = self.bottleneck2(self.max_pool(x))\n",
    "        y = torch.concat([x1, x2, x3, x4], dim=1)\n",
    "        y = torch.nn.functional.relu(self.batch_norm(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, input_size, filters):\n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        self.bottleneck = torch.nn.Conv1d(\n",
    "            in_channels=input_size,\n",
    "            out_channels=4 * filters,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding='same',\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.batch_norm = torch.nn.BatchNorm1d(\n",
    "            num_features=4 * filters\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        y = y + self.batch_norm(self.bottleneck(x))\n",
    "        y = torch.nn.functional.relu(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Lambda(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.f = f\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class InceptionModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes, filters, depth):\n",
    "        super(InceptionModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.filters = filters\n",
    "        self.depth = depth\n",
    "        self.drop=nn.Dropout(p=0.4)\n",
    "        modules = OrderedDict()\n",
    "        \n",
    "        for d in range(depth):\n",
    "            modules[f'inception_{d}'] = Inception(\n",
    "                input_size=input_size if d == 0 else 4 * filters,\n",
    "                filters=filters,\n",
    "            )\n",
    "            if d % 3 == 2:\n",
    "                modules[f'residual_{d}'] = Residual(\n",
    "                    input_size=input_size if d == 2 else 4 * filters,\n",
    "                    filters=filters,\n",
    "                )\n",
    "        \n",
    "        modules['avg_pool'] = Lambda(f=lambda x: torch.mean(x, dim=-1))\n",
    "        # modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=num_classes)\n",
    "        modules['linear1'] = torch.nn.Linear(in_features=4 * filters, out_features=filters)\n",
    "        modules['linear2'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "#         modules['linear3'] = torch.nn.Linear(in_features=filters, out_features=num_classes)\n",
    "        self.model = torch.nn.Sequential(modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for d in range(self.depth):\n",
    "            y = self.model.get_submodule(f'inception_{d}')(x if d == 0 else y)\n",
    "            if d % 3 == 2:\n",
    "                y = self.model.get_submodule(f'residual_{d}')(x, y)\n",
    "                x = y\n",
    "        y = self.model.get_submodule('avg_pool')(y)\n",
    "        y = self.model.get_submodule('linear1')(y)\n",
    "        y = self.drop(F.relu(y))\n",
    "        y = self.model.get_submodule('linear2')(y)\n",
    "#         y = F.relu(self.drop(self.model.get_submodule('linear1')(y)))\n",
    "#         y = F.relu(self.drop(self.model.get_submodule('linear2')(y)))\n",
    "#         y = self.model.get_submodule('linear3')(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiAccuracy(nn.Module):\n",
    "    \"\"\"Accuracy for multi-classification task.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Accuracy module.\"\"\"\n",
    "        super().__init__()\n",
    "        # Counters for correct and total predictions\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "         return self.correct.float() / self.total \n",
    "\n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net2=InceptionModel(\n",
    "                input_size=1,\n",
    "                num_classes=14,\n",
    "                filters=32,\n",
    "                depth=6\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(net2,input_data=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26827df",
   "metadata": {},
   "source": [
    "# 验证集参数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9964c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bde50b",
   "metadata": {},
   "source": [
    "support：当前行的类别在测试数据中的样本总量，如上表就是，在class 0 类别在测试集中总数量为1；<br>\n",
    "precision：精度=正确预测的个数(TP)/被预测正确的个数(TP+FP)；人话也就是模型预测的结果中有多少是预测正确的<br>\n",
    "ecall:召回率=正确预测的个数(TP)/预测个数(TP+FN)；人话也就是某个类别测试集中的总量，有多少样本预测正确了；<br>\n",
    "f1-score:F1 = 2*精度*召回率/(精度+召回率)<br>\n",
    "micro avg：计算所有数据下的指标值，假设全部数据 5 个样本中有 3 个预测正确，所以 micro avg 为 3/5=0.6<br>\n",
    "macro avg：每个类别评估指标未加权的平均值，比如准确率的 macro avg，(0.50+0.00+1.00)/3=0.5<br>\n",
    "weighted avg：加权平均，就是测试集中样本量大的，给他设置的权重大点；比如第一个值的计算方法，(0.50*1 + 0.0*1 + 1.0*3)/5 = 0.70。更好点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dfe55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    " \n",
    "net2.load_state_dict(torch.load('checkpoint_multi_inception'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f40fda",
   "metadata": {},
   "source": [
    "# 评估矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce4944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sklearn.metrics import classification_report\n",
    "net2 = net2.cpu()\n",
    "net2.eval()\n",
    "preds = []\n",
    "believer=[]\n",
    "ytrue=[]\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dl_test):\n",
    "        inputs,labels=batch\n",
    "#         print(inputs.shape)\n",
    "#         print(labels.shape)\n",
    "        \n",
    "        x=net2(inputs)\n",
    "#         print(x.shape)\n",
    "#         be= F.softmax(x, dim=1)\n",
    "        believer.extend(x.tolist())\n",
    "        preds.extend(x.argmax(dim=-1).tolist())\n",
    "        ytrue.extend(labels.tolist())\n",
    "    pprint(len(preds)) \n",
    "    pprint(len(ytrue))\n",
    "    pprint(len(believer))\n",
    "#     pprint(preds) \n",
    "#     pprint(yhat)\n",
    "reportt=classification_report(ytrue,preds)\n",
    "print(reportt)#打印每个类别的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(ytrue,preds)\n",
    "# 将混淆矩阵转换为DataFrame\n",
    "df_cm = pd.DataFrame(cm, index=['True {}'.format(i) for i in range(cm.shape[0])],columns=['Predicted {}'.format(i) for i in range(cm.shape[1])])\n",
    "# pprint(df_cm)\n",
    "# pprint(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e91233",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 25))\n",
    "ax=plt.matshow(cm , cmap=plt.cm.Blues,fignum=1, aspect='auto') \n",
    "cbar=plt.colorbar(ax, fraction=0.05, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "for i in range(len(cm )): \n",
    "    for j in range(len(cm )):\n",
    "        plt.annotate(cm [i,j], xy=(i, j), horizontalalignment='center', verticalalignment='center',fontsize=20)\n",
    "plt.ylabel('真实值标签',fontsize=40)\n",
    "plt.xlabel('预测值标签',fontsize=40) \n",
    "plt.tick_params(axis='both', labelsize=30)\n",
    "plt.savefig('multi-混淆.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97201e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PR\n",
    "import math\n",
    "result_matrix = [[math.exp(element) for element in row] for row in believer] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8477bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1二分类标注\n",
    "# df = pd.DataFrame()\n",
    "tempp=np.array(ytrue)\n",
    "y_test =(tempp==0)\n",
    "#2二分类预测置信度\n",
    "tempr=np.array(result_matrix)\n",
    "y_score = tempr[:,0]\n",
    "y_score\n",
    "#3计算ap\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "AP = average_precision_score(y_test, y_score, average='weighted')\n",
    "AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4计算auc\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c18a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mcolors\n",
    "import random\n",
    "random.seed(124)\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan', 'black', 'indianred', 'brown', 'firebrick', 'maroon', 'darkred', 'red', 'sienna', 'chocolate', 'yellow', 'olivedrab', 'yellowgreen', 'darkolivegreen', 'forestgreen', 'limegreen', 'darkgreen', 'green', 'lime', 'seagreen', 'mediumseagreen', 'darkslategray', 'darkslategrey', 'teal', 'darkcyan', 'dodgerblue', 'navy', 'darkblue', 'mediumblue', 'blue', 'slateblue', 'darkslateblue', 'mediumslateblue', 'mediumpurple', 'rebeccapurple', 'blueviolet', 'indigo', 'darkorchid', 'darkviolet', 'mediumorchid', 'purple', 'darkmagenta', 'fuchsia', 'magenta', 'orchid', 'mediumvioletred', 'deeppink', 'hotpink']\n",
    "markers = [\".\",\",\",\"o\",\"v\",\"^\",\"<\",\">\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "linestyle = ['--', '-.', '-']\n",
    "def get_line_arg():\n",
    "    '''\n",
    "    随机产生一种绘图线型\n",
    "    '''\n",
    "    line_arg = {}\n",
    "    line_arg['color'] = random.choice(colors)\n",
    "    # line_arg['marker'] = random.choice(markers)\n",
    "    line_arg['linestyle'] = random.choice(linestyle)\n",
    "    line_arg['linewidth'] = random.randint(1, 4)\n",
    "    # line_arg['markersize'] = random.randint(3, 5)\n",
    "    return line_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_line_arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "# plt.plot([0, 1], [0, 1],ls=\"--\", c='.3', linewidth=3, label='随机模型')\n",
    "plt.xlabel('召回率',fontsize=25)\n",
    "plt.ylabel('精确率',fontsize=25)\n",
    "plt.rcParams['font.size'] = 22\n",
    "# plt.grid(True)\n",
    "plt.tick_params(labelsize=22) # 设置坐标文字大小\n",
    "ap_list = []\n",
    "for each_class in classes:\n",
    "    y_test = list((tempp == each_class))\n",
    "#     print(len(y_test),each_class)\n",
    "    y_score = list(tempr[:,each_class])\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    AP = average_precision_score(y_test, y_score, average='weighted')\n",
    "    plt.plot(recall, precision, **get_line_arg(), label='label:'+str(each_class))\n",
    "    plt.legend()\n",
    "    ap_list.append(AP)\n",
    "\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.savefig('multi-各类别PR曲线2.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "# plt.plot([0, 1], [0, 1],ls=\"--\", c='.3', linewidth=3, label='随机模型')\n",
    "plt.xlabel('假正率')\n",
    "plt.ylabel('真正率')\n",
    "plt.rcParams['font.size'] = 22\n",
    "# plt.grid(True)\n",
    "\n",
    "auc_list = []\n",
    "for each_class in classes:\n",
    "    y_test = list((tempp == each_class))\n",
    "    y_score = list(tempr[:,each_class])\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "    plt.plot(fpr, tpr, **get_line_arg(), label='label:'+str(each_class))\n",
    "    plt.legend()\n",
    "    auc_list.append(auc(fpr, tpr))\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=15)\n",
    "plt.savefig('multi-各类别ROC曲线.jpg'.format(), dpi=120, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ded11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10757e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存1\n",
    "report=classification_report(ytrue,preds,target_names=classes, output_dict=True)\n",
    "del report['accuracy']\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 ap值 的 宏平均 和 加权平均\n",
    "macro_avg_auc = np.mean(ap_list)\n",
    "# print(len(ap_list))\n",
    "weighted_avg_auc = sum(ap_list * df_report.iloc[:-2]['support'] / len(ytrue))\n",
    "ap_list.append(macro_avg_auc)\n",
    "ap_list.append(weighted_avg_auc)\n",
    "# print(len(ap_list))\n",
    "df_report['AP'] = ap_list\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbba43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 计算 AUC值 的 宏平均 和 加权平均\n",
    "macro_avg_auc = np.mean(auc_list)\n",
    "weighted_avg_auc = sum(auc_list * df_report.iloc[:-2]['support'] / len(ytrue))\n",
    "auc_list.append(macro_avg_auc)\n",
    "auc_list.append(weighted_avg_auc)\n",
    "df_report['AUC'] = auc_list\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_report.to_csv('各类别准确率评估指标.csv', index_label='类别')\n",
    "# df_report.to_csv('各类别准确率评估指标.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0cc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e9d9f8",
   "metadata": {},
   "source": [
    "# 混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810957e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(ytrue,preds)\n",
    "# 将混淆矩阵转换为DataFrame\n",
    "df_cm = pd.DataFrame(cm, index=['True {}'.format(i) for i in range(cm.shape[0])],columns=['Predicted {}'.format(i) for i in range(cm.shape[1])])\n",
    "pprint(df_cm)\n",
    "pprint(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa = cohen_kappa_score(ytrue,preds)\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d628fd5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d04149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1!!!!!!!!!!!!!使用seaborn绘制混淆矩阵、seaborn版本过老\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e629dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2# 使用matplotlib\n",
    "plt.figure(figsize=(20, 20))\n",
    "ax=plt.matshow(cm , cmap=plt.cm.Blues,fignum=1, aspect='auto') \n",
    "cbar=plt.colorbar(ax, fraction=0.05, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "for i in range(len(cm )): \n",
    "    for j in range(len(cm )):\n",
    "        plt.annotate(cm [i,j], xy=(i, j), horizontalalignment='center', verticalalignment='center',fontsize=20)\n",
    "plt.ylabel('True label',fontsize=40)\n",
    "plt.xlabel('Predicted label',fontsize=40) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e35b8",
   "metadata": {},
   "source": [
    "# t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型.pth文件\n",
    "# torch.save(model,'mycheckpoint/saved1.pth')\n",
    "#加载模型\n",
    "#model=torch.load('mycheckpoint/saved1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载网络\n",
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#抽取中间层\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "model_trunc = create_feature_extractor(net2, return_nodes={'model.linear1': 'semantic_feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn([1,1,5000])\n",
    "pred_logits = model_trunc(a) \n",
    "pred_logits['semantic_feature'].squeeze().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dfda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# preds = []\n",
    "preds =torch.empty((0, 32))\n",
    "ll=torch.empty(0)\n",
    "# print(preds.shape)\n",
    "for batch in tqdm(dl_test):\n",
    "    inputs,labels=batch\n",
    "#     print(inputs.shape)\n",
    "    for a in inputs:\n",
    "        a=a.unsqueeze(1)\n",
    "        pred_logits=model_trunc(a)\n",
    "        tmp=pred_logits['semantic_feature'].detach()\n",
    "        preds=torch.cat((preds, tmp), dim=0)\n",
    "    ll=torch.cat((ll,labels), dim=0)\n",
    "# preds=torch.tensor(preds)\n",
    "print(preds.shape)\n",
    "print(ll.shape)\n",
    "tsne_in=np.array(preds)\n",
    "ll_in=np.array(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降维到二维和三维\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, n_iter=20000)\n",
    "X_tsne_2d = tsne.fit_transform(tsne_in)\n",
    "print(X_tsne_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#二维平面可视化\n",
    "import seaborn as sns\n",
    "marker_list = ['.', ',', 'o', 'v', '^', '<', '>', '1', '2', '3', '4', '8', 's', 'p', 'P', '*', 'h', 'H', '+', 'x', 'X', 'D', 'd', '|', '_', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "class_list = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13] ,dtype='float32')\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd4c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = len(class_list) # 测试集标签类别数\n",
    "palette = sns.hls_palette(n_class) # 配色方案\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for idx, typee in enumerate(class_list): # 遍历每个类别\n",
    "    # 获取颜色和点型\n",
    "    color = palette[idx]\n",
    "    marker = marker_list[idx%len(marker_list)]\n",
    "\n",
    "    # 找到所有标注类别为当前类别的图像索引号\n",
    "    indices = np.where(ll_in==typee)\n",
    "    plt.scatter(X_tsne_2d[indices, 0], X_tsne_2d[indices, 1], color=color, marker=marker, label='label:'+str(int(typee)), s=10)\n",
    "\n",
    "plt.legend(fontsize=13, markerscale=2, bbox_to_anchor=(1, 1))#2倍原图例大小，右上角\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig('多维语义特征t-SNE二维降维可视化.jpg', dpi=300) # 保存图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad4bc19",
   "metadata": {},
   "source": [
    "# 1准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import savgol_filter #滤波\n",
    "from sklearn.preprocessing import MinMaxScaler  \n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchkeras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02563f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "wandb.login() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from torch.optim import lr_scheduler\n",
    "config = Namespace(\n",
    "    project_name = \"multipleclass\",\n",
    "    file_path = \"../alldata.csv\",\n",
    "    batch_size = 64,\n",
    "    dropout_p = 0.1,\n",
    "    lr = 1e-4,\n",
    "    optim_type = 'Adam',\n",
    "    epochs = 100,\n",
    "    ckpt_path = 'checkpoint',\n",
    "    num_workers=0\n",
    "    #name\n",
    ")\n",
    "\n",
    "torch.manual_seed(17) #cpu\n",
    "torch.cuda.manual_seed(17) #gpu\n",
    "np.random.seed(17) #numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d84fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        self.alldata=pd.read_csv(filepath,header=None)\n",
    "        self.len=self.alldata.shape[0]\n",
    "        self.alldata=np.array(self.alldata,dtype='float32')\n",
    "        self.xdata=torch.from_numpy(self.alldata[:,0:-2])\n",
    "        self.ydata=torch.from_numpy(self.alldata[:,[-1]])##多分类\n",
    "    def __getitem__(self,index):\n",
    "        xx=self.xdata[index]\n",
    "        lb=savgol_filter(xx, window_length=7, polyorder=2)#Savitzky-Golay 平滑滤波器\n",
    "        scaler=MinMaxScaler()\n",
    "        lb=lb.reshape(-1,1)\n",
    "        lb=scaler.fit_transform(lb)#层归一化\n",
    "        lb=lb.reshape(1,-1)\n",
    "        return lb,self.ydata[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dfdata = MyDataset(config.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "dfdata.ydata=dfdata.ydata.squeeze(1)#\n",
    "dfdata.ydata=dfdata.ydata.to(dtype=torch.int64) #使用交叉熵做损失函数时\n",
    "dftmp, dftest_raw = train_test_split(dfdata, random_state=40, test_size=0.1)\n",
    "dftrain_raw, dfval_raw = train_test_split(dftmp, random_state=40, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51108dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(dftrain) = \",len(dftrain_raw))\n",
    "print(\"len(dfval) = \",len(dfval_raw))\n",
    "print(\"len(dftest) = \",len(dftest_raw))\n",
    "print(dfdata.xdata.shape)\n",
    "print(dfdata.ydata.shape)\n",
    "print(type(dfdata.ydata[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "dl_train =DataLoader(dftrain_raw, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "dl_val =DataLoader(dfval_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "dl_test =DataLoader(dftest_raw, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features,labels in dl_val:\n",
    "    break\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(dl_train.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows操作系统\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签 \n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8)) \n",
    "for i in range(9):\n",
    "    img,label =dftrain_raw[i]\n",
    "    img=img.squeeze(0)\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.plot(np.arange(0,5000),img)\n",
    "    plt.title(label.item())  # 设置标题  \n",
    "    plt.xlabel('time')  # 设置x轴标签  \n",
    "    plt.ylabel('Sales')  #  \n",
    "plt.subplots_adjust(hspace=0.5,wspace=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num0=0\n",
    "num1=0\n",
    "num2=0\n",
    "num3=0\n",
    "num4=0\n",
    "num5=0\n",
    "num6=0\n",
    "num7=0\n",
    "num8=0\n",
    "num9=0\n",
    "num10=0\n",
    "num11=0\n",
    "num12=0\n",
    "num13=0\n",
    "numall=0\n",
    "print(dfdata.ydata[1].item())\n",
    "for i in dfdata.ydata:\n",
    "    if(i.item()==0):\n",
    "        num0+=1\n",
    "    if(i.item()==1):\n",
    "        num1+=1\n",
    "    if(i.item()==2):\n",
    "        num2+=1\n",
    "    if(i.item()==3):\n",
    "        num3+=1\n",
    "    if(i.item()==4):\n",
    "        num4+=1\n",
    "    if(i.item()==5):\n",
    "        num5+=1\n",
    "    if(i.item()==6):\n",
    "        num6+=1\n",
    "    if(i.item()==7):\n",
    "        num7+=1\n",
    "    if(i.item()==8):\n",
    "        num8+=1\n",
    "    if(i.item()==9):\n",
    "        num9+=1\n",
    "    if(i.item()==10):\n",
    "        num10+=1\n",
    "    if(i.item()==11):\n",
    "        num11+=1\n",
    "    if(i.item()==12):\n",
    "        num12+=1\n",
    "    if(i.item()==13):\n",
    "        num13+=1\n",
    "    numall+=1\n",
    "print(numall)\n",
    "fig = plt.figure(figsize=(6,6)) \n",
    "xx=np.array(['class0','class1','class2','class3','class4','class5','class6','class7','class8','class9','class10','class11','class12','class13'])\n",
    "yy=np.array([num0,num1,num2,num3,num4,num5,num6,num7,num8,num9,num10,num11,num12,num13])     \n",
    "plt.pie(yy,labels=xx,autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0141c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#柱状图\n",
    "plt.bar(xx, yy, facecolor='#1f77b4', edgecolor='k')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.xlabel('类别', fontsize=20)\n",
    "plt.ylabel('数量', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "xp = xx\n",
    "ytr = yy*0.72\n",
    "yva = yy*0.18\n",
    "yte=yy*0.1\n",
    "\n",
    "width = 0.5 # 柱状图宽度\n",
    "\n",
    "plt.xticks() # 横轴文字旋转\n",
    "\n",
    "plt.bar(xp, yte, width, label='测试集')\n",
    "plt.bar(xp, yva, width, label='验证集', bottom=yte)\n",
    "plt.bar(xp, ytr, width, label='训练集', bottom=yva)\n",
    "\n",
    "plt.xlabel('类别', fontsize=20)\n",
    "plt.ylabel('数量', fontsize=20)\n",
    "plt.tick_params(labelsize=20) # 设置坐标文字大小\n",
    "\n",
    "plt.legend(fontsize=16,loc='upper right') # 图例\n",
    "\n",
    "# 保存为高清的 pdf 文件\n",
    "# plt.savefig('各类别图像数量.pdf', dpi=120, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7963f8",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):  \n",
    "    def __init__(self, channel, reduction=16):  \n",
    "        super(SELayer, self).__init__()  \n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)  \n",
    "        self.fc = nn.Sequential(  \n",
    "            nn.Linear(channel, channel // reduction, bias=False),  \n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Linear(channel // reduction, channel, bias=False),  \n",
    "            nn.Sigmoid()  \n",
    "        )  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        b, c, _ = x.size()  \n",
    "        y = self.avg_pool(x).view(b, c)  \n",
    "        y = self.fc(y).view(b, c, 1)  \n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class create_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(create_net,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels=1,out_channels=8,kernel_size = 5, stride=1, padding=2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.maxpool= nn.MaxPool1d(2)#等价于nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2=nn.Conv1d(in_channels=8,out_channels=16,kernel_size = 5, stride=1, padding=2)\n",
    "        self.conv3=nn.Conv1d(in_channels=16,out_channels=32,kernel_size = 5, stride=1, padding=2)\n",
    "        self.conv4=nn.Conv1d(in_channels=32,out_channels=64,kernel_size = 5, stride=2, padding=1)\n",
    "        self.conv5=nn.Conv1d(in_channels=64,out_channels=128,kernel_size = 5, stride=1, padding=2)\n",
    "        self.fc1= nn.Linear(128*78,5000)\n",
    "        self.fc2= nn.Linear(5000,2500)\n",
    "        self.fc3= nn.Linear(2500,1000)\n",
    "        self.fc4= nn.Linear(1000,64)\n",
    "        self.fc5= nn.Linear(64,14)\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv5(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=x.view(-1,128*78)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=F.relu(self.fc4(x))\n",
    "        x=self.fc5(x)\n",
    "        output=F.log_softmax(x,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiAccuracy(nn.Module):\n",
    "    \"\"\"Accuracy for multi-classification task.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Accuracy module.\"\"\"\n",
    "        super().__init__()\n",
    "        # Counters for correct and total predictions\n",
    "        self.correct = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.total = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "\n",
    "    def forward(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        m = (preds == targets).sum()\n",
    "        n = targets.shape[0] \n",
    "        self.correct += m \n",
    "        self.total += n\n",
    "        \n",
    "        return m/n\n",
    "\n",
    "    def compute(self):\n",
    "         return self.correct.float() / self.total \n",
    "\n",
    "    def reset(self):\n",
    "        self.correct -= self.correct\n",
    "        self.total -= self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cac677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import summary\n",
    "net = create_net()\n",
    "summary(net,input_data=features);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8899",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练2\n",
    "from torchkeras import KerasModel\n",
    "#对多分类模型来说，要用Macro Average（宏平均）或Micro Average（微平均）规则来进行F1（或者P、R）的计算。\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score#使用函数调转真实值与预测值的位置precision_score(labels, preds, average='macro')\n",
    "# net = create_net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.Adam(net.parameters(),lr=config.lr)\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "metric_dict = {\"acc\":multiAccuracy()}\n",
    "model = KerasModel(net,\n",
    "                   loss_fn = loss_fn,\n",
    "                   metrics_dict= metric_dict,\n",
    "                   optimizer = optimizer\n",
    "#                    ,\n",
    "#                    lr_scheduler=lr_scheduler\n",
    "                  )   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67014c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.kerascallbacks import WandbCallback\n",
    "wandb_cb = WandbCallback(project=config.project_name,\n",
    "                         config=config,\n",
    "                         name=None,\n",
    "                         save_code=True,\n",
    "                         save_ckpt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory = model.fit(\n",
    "      train_data=dl_train,\n",
    "      val_data=dl_val,\n",
    "      epochs=config.epochs,\n",
    "      ckpt_path='checkpoint',\n",
    "      patience=40,\n",
    "      monitor='val_acc',\n",
    "      mode='max',\n",
    "      callbacks = [wandb_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee8423",
   "metadata": {},
   "source": [
    "# 训练集、测试集评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5869d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfhistory['val_loss'].min())\n",
    "print(dfhistory['train_loss'].min())\n",
    "print(dfhistory['val_acc'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
